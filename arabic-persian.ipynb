{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f8ebbd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:32.844407Z",
     "iopub.status.busy": "2023-12-02T16:34:32.843245Z",
     "iopub.status.idle": "2023-12-02T16:34:38.408380Z",
     "shell.execute_reply": "2023-12-02T16:34:38.406878Z"
    },
    "papermill": {
     "duration": 5.576443,
     "end_time": "2023-12-02T16:34:38.410923",
     "exception": false,
     "start_time": "2023-12-02T16:34:32.834480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "from torch import optim as opt\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing \n",
    "from torchvision import transforms\n",
    "import imageio as iio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a299668b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:38.424003Z",
     "iopub.status.busy": "2023-12-02T16:34:38.423493Z",
     "iopub.status.idle": "2023-12-02T16:34:38.428509Z",
     "shell.execute_reply": "2023-12-02T16:34:38.427109Z"
    },
    "papermill": {
     "duration": 0.014434,
     "end_time": "2023-12-02T16:34:38.431151",
     "exception": false,
     "start_time": "2023-12-02T16:34:38.416717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 48\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fa4a1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:38.444056Z",
     "iopub.status.busy": "2023-12-02T16:34:38.443667Z",
     "iopub.status.idle": "2023-12-02T16:34:39.845054Z",
     "shell.execute_reply": "2023-12-02T16:34:39.843711Z"
    },
    "papermill": {
     "duration": 1.410526,
     "end_time": "2023-12-02T16:34:39.847408",
     "exception": false,
     "start_time": "2023-12-02T16:34:38.436882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['Amin','Farzad','Maziar','Mehrdad','Sina','Soheil','Vahid']\n",
    "name_file = {name:[] for name in names}\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/arabicpersian-handwritten-cities-for-postal-apps/scan splited/scan splited'):\n",
    "    filenames = sorted(filenames) # i want it to be on the same order\n",
    "    for filename in filenames:\n",
    "        name = dirname[89:]\n",
    "        name_file[name].append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139c0160",
   "metadata": {
    "papermill": {
     "duration": 0.00492,
     "end_time": "2023-12-02T16:34:39.857919",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.852999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# I just want to take a subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ee086a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.870777Z",
     "iopub.status.busy": "2023-12-02T16:34:39.870408Z",
     "iopub.status.idle": "2023-12-02T16:34:39.876697Z",
     "shell.execute_reply": "2023-12-02T16:34:39.874996Z"
    },
    "papermill": {
     "duration": 0.015303,
     "end_time": "2023-12-02T16:34:39.878579",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.863276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "alphabit = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويئ\"\n",
    "num_output = len(alphabit)\n",
    "alphabit = [a for a in alphabit]\n",
    "print(num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36c5f80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.892384Z",
     "iopub.status.busy": "2023-12-02T16:34:39.891388Z",
     "iopub.status.idle": "2023-12-02T16:34:39.897118Z",
     "shell.execute_reply": "2023-12-02T16:34:39.896124Z"
    },
    "papermill": {
     "duration": 0.014196,
     "end_time": "2023-12-02T16:34:39.898818",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.884622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_words(targets):\n",
    "    \"\"\"\n",
    "    Padding words to make all of them on the same size\n",
    "    \"\"\"\n",
    "    targets_new = []\n",
    "    for target in targets:\n",
    "        pad = 6-len(target)\n",
    "        targets_new.append(np.concatenate((np.ones(pad),target),axis=0).astype(np.longlong))\n",
    "        \n",
    "        \n",
    "    return targets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b46e3852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.912289Z",
     "iopub.status.busy": "2023-12-02T16:34:39.911295Z",
     "iopub.status.idle": "2023-12-02T16:34:39.928676Z",
     "shell.execute_reply": "2023-12-02T16:34:39.927422Z"
    },
    "papermill": {
     "duration": 0.026541,
     "end_time": "2023-12-02T16:34:39.931146",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.904605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = (\" خيابان ميدان نمين ديلم مهران كاشان برحوار نائين البرز يزد تبريز سيريك\") # only these words will be considerd\n",
    "words = words*4 # four persons wrote these words\n",
    "words = words.split(' ')\n",
    "words.__delitem__(0) # first element is just empty\n",
    "\n",
    "\n",
    "imgs = []\n",
    "for name,files in name_file.items():\n",
    "    if  name.__eq__('Maziar') or name.__eq__('Mehrdad') or name.__eq__('Sina'):\n",
    "        continue\n",
    "    for i,file in enumerate(files):\n",
    "        if i == 12:\n",
    "            break\n",
    "        imgs.append(file)\n",
    "    \n",
    "\n",
    "targets = [[w for w in word] for word in words]\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "lbl_enc.fit(alphabit)\n",
    "targets_enc = [lbl_enc.transform(word)+1 for word in targets]\n",
    "targets_enc = pad_words(targets_enc)\n",
    "dataset = {'imgs':imgs, \"labels\":targets_enc}\n",
    "df = pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8e8f4",
   "metadata": {
    "papermill": {
     "duration": 0.005241,
     "end_time": "2023-12-02T16:34:39.942158",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.936917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b3d486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.955353Z",
     "iopub.status.busy": "2023-12-02T16:34:39.954981Z",
     "iopub.status.idle": "2023-12-02T16:34:39.961444Z",
     "shell.execute_reply": "2023-12-02T16:34:39.959866Z"
    },
    "papermill": {
     "duration": 0.016572,
     "end_time": "2023-12-02T16:34:39.963995",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.947423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,trans=None):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = Image.open(self.df['imgs'][idx]).convert('RGB')\n",
    "        if trans:\n",
    "            x = trans(x)\n",
    "        y = self.df['labels'][idx] # +1 i have already add one in the above cell \n",
    "        return (x,y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd80cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.976584Z",
     "iopub.status.busy": "2023-12-02T16:34:39.976214Z",
     "iopub.status.idle": "2023-12-02T16:34:39.980833Z",
     "shell.execute_reply": "2023-12-02T16:34:39.979682Z"
    },
    "papermill": {
     "duration": 0.013803,
     "end_time": "2023-12-02T16:34:39.983520",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.969717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std = torch.tensor([0.0603, 0.0606, 0.0347])\n",
    "# mean = torch.tensor([[0.8753, 0.8924, 0.9244]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64540bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:39.996455Z",
     "iopub.status.busy": "2023-12-02T16:34:39.996067Z",
     "iopub.status.idle": "2023-12-02T16:34:40.003192Z",
     "shell.execute_reply": "2023-12-02T16:34:40.001572Z"
    },
    "papermill": {
     "duration": 0.016369,
     "end_time": "2023-12-02T16:34:40.005810",
     "exception": false,
     "start_time": "2023-12-02T16:34:39.989441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(20,80)),\n",
    "    transforms.Normalize(mean=(0.8753,0.8924,0.9244),std=(0.0603,0.0606,0.0347))\n",
    "                           ])\n",
    "all_imgs = []\n",
    "dataset = Mydataset(df,trans)\n",
    "\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=bs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b609a",
   "metadata": {
    "papermill": {
     "duration": 0.00532,
     "end_time": "2023-12-02T16:34:40.017056",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.011736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b02f038e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:40.030021Z",
     "iopub.status.busy": "2023-12-02T16:34:40.029639Z",
     "iopub.status.idle": "2023-12-02T16:34:40.080065Z",
     "shell.execute_reply": "2023-12-02T16:34:40.078498Z"
    },
    "papermill": {
     "duration": 0.060028,
     "end_time": "2023-12-02T16:34:40.082532",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.022504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ح'], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  torch.tensor([ [ [1,2,3],[5,6,4] ],[[1,1,1],[2,2,2]] ])\n",
    "aaa = torch.argmax(test,dim=1)  \n",
    "# lbl_enc.inverse_transform\n",
    "a = [ t.shape for t in aaa]\n",
    "aaa.shape\n",
    "\n",
    "lbl_enc.inverse_transform(np.array([6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a9428d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:40.096858Z",
     "iopub.status.busy": "2023-12-02T16:34:40.096510Z",
     "iopub.status.idle": "2023-12-02T16:34:40.103633Z",
     "shell.execute_reply": "2023-12-02T16:34:40.102431Z"
    },
    "papermill": {
     "duration": 0.017072,
     "end_time": "2023-12-02T16:34:40.105557",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.088485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decode_pred(y_pred,targets):\n",
    "    \"\"\"\n",
    "    convert numbers to its corresponding characters \n",
    "    0 -> blank\n",
    "    1 -> padding\n",
    "    y_pred : output of the model [T,bs,num_classes]\n",
    "    targets : the ground truth [bs,num of characters]\n",
    "    \"\"\"\n",
    "    y_pred = torch.argmax(y_pred,dim=2)  \n",
    "    # now our tensor is [T,bs] , in each time stamp there is the charecter with the highest probablity \n",
    "    y_pred = y_pred.permute(1,0) # [bs,T]\n",
    "    labels = [decode_word(word) for word in y_pred]\n",
    "    \n",
    "    # if 0 then its blank , replace it with ?\n",
    "    return labels\n",
    "    \n",
    "def decode_word(word):\n",
    "    \"\"\"\n",
    "    covert numbers to words\n",
    "    words shape: [T] the highest probabilty in each time stamp\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for character in word:\n",
    "        character -= 2 \n",
    "        if character.item() == -2 :\n",
    "            characters.append(\"?\")\n",
    "        elif character.item() == -1:\n",
    "            characters.append(\"P\")\n",
    "        else:\n",
    "            characters.append(lbl_enc.inverse_transform([character]))        \n",
    "    \n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030505a",
   "metadata": {
    "papermill": {
     "duration": 0.005426,
     "end_time": "2023-12-02T16:34:40.117113",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.111687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5849c6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:40.129794Z",
     "iopub.status.busy": "2023-12-02T16:34:40.129374Z",
     "iopub.status.idle": "2023-12-02T16:34:40.144225Z",
     "shell.execute_reply": "2023-12-02T16:34:40.143158Z"
    },
    "papermill": {
     "duration": 0.024362,
     "end_time": "2023-12-02T16:34:40.146916",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.122554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_map = torch.tensor([48, 84, 5, 20]) # bs,c,h,w\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,12,3,2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(12,36,3,2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(36,84,3,1,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv2(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv3(F.relu(x))\n",
    "        return x\n",
    "    \n",
    "class MyRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_layers,bi):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers        \n",
    "        self.bi = bi\n",
    "        self.D = 2 if self.bi else 1 \n",
    "        self.gru = nn.GRU(input_size,hidden_size,num_layers,bidirectional=bi,batch_first=True)\n",
    "        self.linear1 = nn.Linear(self.D*hidden_size,self.D*hidden_size)\n",
    "        self.linear2 = nn.Linear(self.D*hidden_size,num_output+2) # +1 for the blank ctc\n",
    "        \n",
    "        \n",
    "    def forward(self,x): \n",
    "        h0 = torch.zeros(self.D*self.num_layers,x.size(0),self.hidden_size)\n",
    "        out,hn = self.gru(x,h0)\n",
    "        out = self.linear1(F.relu(out))\n",
    "        out = self.linear2(out)\n",
    "        out = F.log_softmax(out,dim=2)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "# class denseLayer(nn.Module):\n",
    "#     def __init__\n",
    "    \n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_size,num_layers,bi):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers  \n",
    "        self.bi = bi\n",
    "        self.cnn = MyCNN()\n",
    "        self.rnn = MyRNN(feature_map[1]*feature_map[2],hidden_size,num_layers,bi)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "#         print(x.shape) # --> (bs,c,h,w)\n",
    "        x = x.view(-1,x.shape[3],x.shape[2]*x.shape[1]) # --> (bs,w,h*c)\n",
    "        \n",
    "        # i will assume that num of channels is the time_stamps \n",
    "        # i've changed my mind :) , w = time_stamps\n",
    "        # for rnn , we need (time_stamps,bs,featuers)\n",
    "        \n",
    "        x = x.permute(1,0,2) \n",
    "#         print(x.shape)\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f501cf85",
   "metadata": {
    "papermill": {
     "duration": 0.005234,
     "end_time": "2023-12-02T16:34:40.157971",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.152737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db6e93e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:34:40.170567Z",
     "iopub.status.busy": "2023-12-02T16:34:40.170165Z",
     "iopub.status.idle": "2023-12-02T16:46:06.094745Z",
     "shell.execute_reply": "2023-12-02T16:46:06.093619Z"
    },
    "papermill": {
     "duration": 685.934159,
     "end_time": "2023-12-02T16:46:06.097591",
     "exception": false,
     "start_time": "2023-12-02T16:34:40.163432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_fn =  nn.CTCLoss(blank=0)\n",
    "model = MyModel(300,2,True)\n",
    "lr = 1e-3\n",
    "optim = opt.Adam(model.parameters(),lr=lr) \n",
    "\n",
    "batch = next(iter(train_loader))       \n",
    "train_loss = []\n",
    "for epoch in range (2000):\n",
    "    losses = 0\n",
    "    for batch in train_loader:\n",
    "        x,y = batch[0],batch[1]\n",
    "        out = model(batch[0])\n",
    "        input_lengths = torch.full(size=(x.shape[0],), fill_value=out.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(x.shape[0],), fill_value=batch[1].size(1), dtype=torch.long)\n",
    "        optim.zero_grad()\n",
    "        loss = loss_fn(out,batch[1],input_lengths,target_lengths)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "    train_loss.append(losses/len(train_loader))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12952b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.110570Z",
     "iopub.status.busy": "2023-12-02T16:46:06.110183Z",
     "iopub.status.idle": "2023-12-02T16:46:06.324742Z",
     "shell.execute_reply": "2023-12-02T16:46:06.323661Z"
    },
    "papermill": {
     "duration": 0.223388,
     "end_time": "2023-12-02T16:46:06.326882",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.103494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x78124fa8df00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e4f502d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.341063Z",
     "iopub.status.busy": "2023-12-02T16:46:06.340667Z",
     "iopub.status.idle": "2023-12-02T16:46:06.356230Z",
     "shell.execute_reply": "2023-12-02T16:46:06.354829Z"
    },
    "papermill": {
     "duration": 0.024965,
     "end_time": "2023-12-02T16:46:06.358271",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.333306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.790457725524902,\n",
       " 8.207406044006348,\n",
       " 6.984409332275391,\n",
       " 4.438624858856201,\n",
       " 3.599921226501465,\n",
       " 3.604987382888794,\n",
       " 3.0826332569122314,\n",
       " 2.990666627883911,\n",
       " 2.8417418003082275,\n",
       " 2.7634410858154297,\n",
       " 2.6712048053741455,\n",
       " 2.620198965072632,\n",
       " 2.565478801727295,\n",
       " 2.512031078338623,\n",
       " 2.433480978012085,\n",
       " 2.352081060409546,\n",
       " 2.323199987411499,\n",
       " 2.2875287532806396,\n",
       " 2.2465391159057617,\n",
       " 2.2217648029327393,\n",
       " 2.1903584003448486,\n",
       " 2.153270721435547,\n",
       " 2.116778612136841,\n",
       " 2.0851566791534424,\n",
       " 2.0593631267547607,\n",
       " 2.0396602153778076,\n",
       " 2.020648241043091,\n",
       " 1.9971922636032104,\n",
       " 1.972448468208313,\n",
       " 1.9493001699447632,\n",
       " 1.9283140897750854,\n",
       " 1.9090365171432495,\n",
       " 1.890275001525879,\n",
       " 1.871810793876648,\n",
       " 1.8533930778503418,\n",
       " 1.8351160287857056,\n",
       " 1.818277359008789,\n",
       " 1.804932713508606,\n",
       " 1.7930353879928589,\n",
       " 1.7804237604141235,\n",
       " 1.7679672241210938,\n",
       " 1.7564144134521484,\n",
       " 1.746039867401123,\n",
       " 1.735289216041565,\n",
       " 1.7252439260482788,\n",
       " 1.714356541633606,\n",
       " 1.7041343450546265,\n",
       " 1.6930187940597534,\n",
       " 1.681503176689148,\n",
       " 1.6698369979858398,\n",
       " 1.6590031385421753,\n",
       " 1.6470355987548828,\n",
       " 1.6344165802001953,\n",
       " 1.6236190795898438,\n",
       " 1.6194968223571777,\n",
       " 1.6273612976074219,\n",
       " 1.6128758192062378,\n",
       " 1.5811271667480469,\n",
       " 1.5772581100463867,\n",
       " 1.5767003297805786,\n",
       " 1.5594364404678345,\n",
       " 1.5381852388381958,\n",
       " 1.5410047769546509,\n",
       " 1.522128701210022,\n",
       " 1.5054311752319336,\n",
       " 1.4861282110214233,\n",
       " 1.486030101776123,\n",
       " 1.471875786781311,\n",
       " 1.4417835474014282,\n",
       " 1.4407720565795898,\n",
       " 1.4210747480392456,\n",
       " 1.38941490650177,\n",
       " 1.3848074674606323,\n",
       " 1.3769874572753906,\n",
       " 1.3503870964050293,\n",
       " 1.3641830682754517,\n",
       " 1.341004490852356,\n",
       " 1.3185161352157593,\n",
       " 1.2919992208480835,\n",
       " 1.2623690366744995,\n",
       " 1.2312476634979248,\n",
       " 1.2155342102050781,\n",
       " 1.1586443185806274,\n",
       " 1.1415644884109497,\n",
       " 1.089084267616272,\n",
       " 1.0737906694412231,\n",
       " 1.0487422943115234,\n",
       " 0.9925373196601868,\n",
       " 0.9657900333404541,\n",
       " 0.9152753949165344,\n",
       " 0.8772168755531311,\n",
       " 0.8389796614646912,\n",
       " 0.8082883358001709,\n",
       " 0.7622535824775696,\n",
       " 0.7213692665100098,\n",
       " 0.6790533661842346,\n",
       " 0.6471149325370789,\n",
       " 0.6022897362709045,\n",
       " 0.5655288696289062,\n",
       " 0.5244909524917603,\n",
       " 0.49725160002708435,\n",
       " 0.45576369762420654,\n",
       " 0.422753244638443,\n",
       " 0.3928031027317047,\n",
       " 0.3638159930706024,\n",
       " 0.33138808608055115,\n",
       " 0.308415025472641,\n",
       " 0.28249451518058777,\n",
       " 0.2580605447292328,\n",
       " 0.23804712295532227,\n",
       " 0.21844494342803955,\n",
       " 0.1984490156173706,\n",
       " 0.17951911687850952,\n",
       " 0.1649547666311264,\n",
       " 0.1495143324136734,\n",
       " 0.1345333606004715,\n",
       " 0.12109658867120743,\n",
       " 0.1091303750872612,\n",
       " 0.09767797589302063,\n",
       " 0.0867481529712677,\n",
       " 0.07756649702787399,\n",
       " 0.06891735643148422,\n",
       " 0.061603326350450516,\n",
       " 0.054723065346479416,\n",
       " 0.048741016536951065,\n",
       " 0.04351814091205597,\n",
       " 0.03914038464426994,\n",
       " 0.035094618797302246,\n",
       " 0.03177536651492119,\n",
       " 0.02865506522357464,\n",
       " 0.02575942687690258,\n",
       " 0.023294446989893913,\n",
       " 0.021305790171027184,\n",
       " 0.019587261602282524,\n",
       " 0.0180272925645113,\n",
       " 0.016650879755616188,\n",
       " 0.015457523055374622,\n",
       " 0.014351495541632175,\n",
       " 0.013373780064284801,\n",
       " 0.012512288056313992,\n",
       " 0.011717968620359898,\n",
       " 0.011012411676347256,\n",
       " 0.010384283028542995,\n",
       " 0.009801015257835388,\n",
       " 0.009277579374611378,\n",
       " 0.008810333907604218,\n",
       " 0.008386929519474506,\n",
       " 0.007999485358595848,\n",
       " 0.007645862177014351,\n",
       " 0.007319290190935135,\n",
       " 0.007017383351922035,\n",
       " 0.006741821300238371,\n",
       " 0.006495961919426918,\n",
       " 0.006266508251428604,\n",
       " 0.006052311509847641,\n",
       " 0.005846209824085236,\n",
       " 0.005655018147081137,\n",
       " 0.005471348762512207,\n",
       " 0.0053069740533828735,\n",
       " 0.005145838484168053,\n",
       " 0.005000845994800329,\n",
       " 0.00486243749037385,\n",
       " 0.004735838156193495,\n",
       " 0.004614772740751505,\n",
       " 0.004499657545238733,\n",
       " 0.0043907808139920235,\n",
       " 0.004286913201212883,\n",
       " 0.004189061466604471,\n",
       " 0.0040952167473733425,\n",
       " 0.0040087467059493065,\n",
       " 0.003924089018255472,\n",
       " 0.00384335033595562,\n",
       " 0.0037675118073821068,\n",
       " 0.003694426268339157,\n",
       " 0.0036252590361982584,\n",
       " 0.003558433847501874,\n",
       " 0.0034948140382766724,\n",
       " 0.0034335486125200987,\n",
       " 0.003374885767698288,\n",
       " 0.0033176986034959555,\n",
       " 0.0032637135591357946,\n",
       " 0.003210926428437233,\n",
       " 0.00315955001860857,\n",
       " 0.003111224854364991,\n",
       " 0.0030640505719929934,\n",
       " 0.003017345443367958,\n",
       " 0.0029740796890109777,\n",
       " 0.0029295070562511683,\n",
       " 0.0028868550434708595,\n",
       " 0.0028459460008889437,\n",
       " 0.002804313786327839,\n",
       " 0.0027646131347864866,\n",
       " 0.002727954415604472,\n",
       " 0.0026893604081124067,\n",
       " 0.002652602968737483,\n",
       " 0.002619358943775296,\n",
       " 0.002583147957921028,\n",
       " 0.0025506909005343914,\n",
       " 0.0025182771496474743,\n",
       " 0.002485480858013034,\n",
       " 0.002455378184095025,\n",
       " 0.0024256675969809294,\n",
       " 0.002394758863374591,\n",
       " 0.0023666266351938248,\n",
       " 0.0023377796169370413,\n",
       " 0.0023094292264431715,\n",
       " 0.002283340087160468,\n",
       " 0.0022572088055312634,\n",
       " 0.002230769256129861,\n",
       " 0.0022067225072532892,\n",
       " 0.00218195584602654,\n",
       " 0.0021567342337220907,\n",
       " 0.0021335501223802567,\n",
       " 0.002111000707373023,\n",
       " 0.0020871052984148264,\n",
       " 0.002065153094008565,\n",
       " 0.0020432835444808006,\n",
       " 0.002021544147282839,\n",
       " 0.002000492997467518,\n",
       " 0.001980457454919815,\n",
       " 0.001959883840754628,\n",
       " 0.0019395668059587479,\n",
       " 0.0019196629291400313,\n",
       " 0.0019005187787115574,\n",
       " 0.0018818681128323078,\n",
       " 0.0018627251265570521,\n",
       " 0.0018443054286763072,\n",
       " 0.0018261148361489177,\n",
       " 0.0018081056186929345,\n",
       " 0.001790657639503479,\n",
       " 0.0017734058201313019,\n",
       " 0.0017568889306858182,\n",
       " 0.0017418420175090432,\n",
       " 0.0017245773924514651,\n",
       " 0.001707718358375132,\n",
       " 0.0016916444292291999,\n",
       " 0.0016762708546593785,\n",
       " 0.0016614190535619855,\n",
       " 0.0016461154446005821,\n",
       " 0.0016305181197822094,\n",
       " 0.0016160585219040513,\n",
       " 0.0016014989232644439,\n",
       " 0.0015882531879469752,\n",
       " 0.0015741927782073617,\n",
       " 0.0015604057116433978,\n",
       " 0.0015474208630621433,\n",
       " 0.00153458456043154,\n",
       " 0.0015224465169012547,\n",
       " 0.0015085405902937055,\n",
       " 0.0014979647239670157,\n",
       " 0.001485021784901619,\n",
       " 0.0014717155136168003,\n",
       " 0.0014614904066547751,\n",
       " 0.0014480199897661805,\n",
       " 0.001437812577933073,\n",
       " 0.0014256398426368833,\n",
       " 0.0014138157712295651,\n",
       " 0.0014034354826435447,\n",
       " 0.0013915542513132095,\n",
       " 0.0013812981778755784,\n",
       " 0.0013702213764190674,\n",
       " 0.0013593091862276196,\n",
       " 0.0013493127189576626,\n",
       " 0.001338391681201756,\n",
       " 0.0013285600580275059,\n",
       " 0.0013190611498430371,\n",
       " 0.00130824267398566,\n",
       " 0.0012988625094294548,\n",
       " 0.0012897929409518838,\n",
       " 0.0012798121897503734,\n",
       " 0.0012699700891971588,\n",
       " 0.0012608012184500694,\n",
       " 0.001251675421372056,\n",
       " 0.0012424299493432045,\n",
       " 0.0012334929779171944,\n",
       " 0.0012251305161044002,\n",
       " 0.0012167285894975066,\n",
       " 0.0012079569278284907,\n",
       " 0.0011989619815722108,\n",
       " 0.0011905739083886147,\n",
       " 0.0011827923590317369,\n",
       " 0.001174895209260285,\n",
       " 0.0011661192402243614,\n",
       " 0.00115808320697397,\n",
       " 0.0011500074760988355,\n",
       " 0.0011424104450270534,\n",
       " 0.0011347337858751416,\n",
       " 0.0011269632959738374,\n",
       " 0.00111964822281152,\n",
       " 0.0011127698235213757,\n",
       " 0.0011048889718949795,\n",
       " 0.0010974077740684152,\n",
       " 0.001090071746148169,\n",
       " 0.0010828700615093112,\n",
       " 0.0010759407887235284,\n",
       " 0.0010692442301660776,\n",
       " 0.0010623784037306905,\n",
       " 0.0010550926672294736,\n",
       " 0.0010481450008228421,\n",
       " 0.0010414342395961285,\n",
       " 0.0010351085802540183,\n",
       " 0.0010287041077390313,\n",
       " 0.0010218893876299262,\n",
       " 0.0010153331095352769,\n",
       " 0.001008855877444148,\n",
       " 0.0010024079820141196,\n",
       " 0.0009961206233128905,\n",
       " 0.0009899487486109138,\n",
       " 0.00098415557295084,\n",
       " 0.0009790422627702355,\n",
       " 0.0009717685752548277,\n",
       " 0.0009657273185439408,\n",
       " 0.0009604270453564823,\n",
       " 0.0009542045299895108,\n",
       " 0.000948227068874985,\n",
       " 0.0009424244053661823,\n",
       " 0.0009369048639200628,\n",
       " 0.0009314822382293642,\n",
       " 0.0009259002399630845,\n",
       " 0.000920032849535346,\n",
       " 0.0009144744253717363,\n",
       " 0.0009091291576623917,\n",
       " 0.0009038907592184842,\n",
       " 0.0008982183062471449,\n",
       " 0.0008929509785957634,\n",
       " 0.0008881526882760227,\n",
       " 0.0008825695258565247,\n",
       " 0.0008773293229751289,\n",
       " 0.0008722792845219374,\n",
       " 0.0008671068935655057,\n",
       " 0.0008621196611784399,\n",
       " 0.000857190228998661,\n",
       " 0.000852176221087575,\n",
       " 0.0008474797941744328,\n",
       " 0.0008427331340499222,\n",
       " 0.0008376082987524569,\n",
       " 0.0008325872477144003,\n",
       " 0.000827991811092943,\n",
       " 0.0008232453837990761,\n",
       " 0.0008186755585484207,\n",
       " 0.0008137411787174642,\n",
       " 0.0008092177449725568,\n",
       " 0.0008049619500525296,\n",
       " 0.0008004276896826923,\n",
       " 0.0007956232293508947,\n",
       " 0.000791247293818742,\n",
       " 0.0007869903929531574,\n",
       " 0.0007827540975995362,\n",
       " 0.0007781652384437621,\n",
       " 0.0007737047853879631,\n",
       " 0.0007696224492974579,\n",
       " 0.000765242672059685,\n",
       " 0.0007611654582433403,\n",
       " 0.000757009896915406,\n",
       " 0.0007531009614467621,\n",
       " 0.0007490128627978265,\n",
       " 0.0007454373990185559,\n",
       " 0.0007411735132336617,\n",
       " 0.0007369687664322555,\n",
       " 0.0007331228698603809,\n",
       " 0.0007294295937754214,\n",
       " 0.0007255952805280685,\n",
       " 0.0007214313372969627,\n",
       " 0.0007180142565630376,\n",
       " 0.0007140489760786295,\n",
       " 0.0007100824150256813,\n",
       " 0.0007065040990710258,\n",
       " 0.0007027616375125945,\n",
       " 0.0006989793037064373,\n",
       " 0.0006953378324396908,\n",
       " 0.000691946770530194,\n",
       " 0.0006880522123537958,\n",
       " 0.0006846137694083154,\n",
       " 0.0006813456420786679,\n",
       " 0.000677431293297559,\n",
       " 0.0006738759111613035,\n",
       " 0.0006704131956212223,\n",
       " 0.0006670229486189783,\n",
       " 0.0006637475453317165,\n",
       " 0.0006601947243325412,\n",
       " 0.0006567665841430426,\n",
       " 0.0006534765125252306,\n",
       " 0.000650230620522052,\n",
       " 0.0006470611551776528,\n",
       " 0.0006442163721658289,\n",
       " 0.0006413398659788072,\n",
       " 0.000637600664049387,\n",
       " 0.000634826603345573,\n",
       " 0.0006320253014564514,\n",
       " 0.0006284076953306794,\n",
       " 0.0006262451061047614,\n",
       " 0.000622337858658284,\n",
       " 0.0006197604234330356,\n",
       " 0.0006163478246890008,\n",
       " 0.0006136816227808595,\n",
       " 0.0006104716449044645,\n",
       " 0.0006076414720155299,\n",
       " 0.0006046369671821594,\n",
       " 0.0006016544648446143,\n",
       " 0.0005988135817460716,\n",
       " 0.0005960636190138757,\n",
       " 0.0005931483465246856,\n",
       " 0.0005903878482058644,\n",
       " 0.0005875309580005705,\n",
       " 0.0005847804713994265,\n",
       " 0.0005820571095682681,\n",
       " 0.0005793574382551014,\n",
       " 0.0005766162066720426,\n",
       " 0.000574057805351913,\n",
       " 0.0005716087180189788,\n",
       " 0.0005688004312105477,\n",
       " 0.0005660870228894055,\n",
       " 0.000563521112781018,\n",
       " 0.000561249500606209,\n",
       " 0.0005586713086813688,\n",
       " 0.0005558527773246169,\n",
       " 0.0005533981020562351,\n",
       " 0.0005510638002306223,\n",
       " 0.0005483822897076607,\n",
       " 0.0005459647509269416,\n",
       " 0.0005438213120214641,\n",
       " 0.0005409973673522472,\n",
       " 0.0005392248858697712,\n",
       " 0.000536769803147763,\n",
       " 0.0005339676281437278,\n",
       " 0.0005322292563505471,\n",
       " 0.0005292773712426424,\n",
       " 0.0005272608832456172,\n",
       " 0.0005246553919278085,\n",
       " 0.0005226331413723528,\n",
       " 0.0005201108288019896,\n",
       " 0.0005179107538424432,\n",
       " 0.0005156653933227062,\n",
       " 0.0005132905207574368,\n",
       " 0.0005111402715556324,\n",
       " 0.0005087825702503324,\n",
       " 0.0005067020538263023,\n",
       " 0.0005045612924732268,\n",
       " 0.0005022585391998291,\n",
       " 0.0005002760444767773,\n",
       " 0.0004982276004739106,\n",
       " 0.000495854823384434,\n",
       " 0.0004941523657180369,\n",
       " 0.0004919223138131201,\n",
       " 0.000489677069708705,\n",
       " 0.0004877396859228611,\n",
       " 0.00048559147398918867,\n",
       " 0.00048345825052820146,\n",
       " 0.0004815027641598135,\n",
       " 0.0004793688713107258,\n",
       " 0.00047742141759954393,\n",
       " 0.000475584645755589,\n",
       " 0.0004735649563372135,\n",
       " 0.000471398961963132,\n",
       " 0.0004694958042819053,\n",
       " 0.00046780009870417416,\n",
       " 0.0004655323864426464,\n",
       " 0.00046387090696953237,\n",
       " 0.0004621786065399647,\n",
       " 0.00045987413614057004,\n",
       " 0.0004583557602018118,\n",
       " 0.00045616726856678724,\n",
       " 0.00045444609713740647,\n",
       " 0.00045251252595335245,\n",
       " 0.0004505865217652172,\n",
       " 0.00044887783587910235,\n",
       " 0.0004469051491469145,\n",
       " 0.0004452591820154339,\n",
       " 0.0004435246519278735,\n",
       " 0.00044151852489449084,\n",
       " 0.00044001630158163607,\n",
       " 0.0004381937033031136,\n",
       " 0.00043625858961604536,\n",
       " 0.00043470459058880806,\n",
       " 0.00043284831917844713,\n",
       " 0.0004310950171202421,\n",
       " 0.00042954759555868804,\n",
       " 0.0004276137624401599,\n",
       " 0.0004260720743332058,\n",
       " 0.0004244232550263405,\n",
       " 0.0004225616867188364,\n",
       " 0.00042112264782190323,\n",
       " 0.0004193213244434446,\n",
       " 0.000417736591771245,\n",
       " 0.00041639883420430124,\n",
       " 0.0004143434634897858,\n",
       " 0.00041315003181807697,\n",
       " 0.00041135013452731073,\n",
       " 0.0004096587945241481,\n",
       " 0.00040812010411173105,\n",
       " 0.00040642867679707706,\n",
       " 0.0004049614944960922,\n",
       " 0.00040330729098059237,\n",
       " 0.0004017398750875145,\n",
       " 0.00040026227361522615,\n",
       " 0.0003986404917668551,\n",
       " 0.00039709985139779747,\n",
       " 0.00039561488665640354,\n",
       " 0.00039409357123076916,\n",
       " 0.00039258296601474285,\n",
       " 0.0003911160456482321,\n",
       " 0.00038979738019406796,\n",
       " 0.0003886564227286726,\n",
       " 0.0003867399354930967,\n",
       " 0.0003857692936435342,\n",
       " 0.00038414166192524135,\n",
       " 0.0003825482854153961,\n",
       " 0.00038138250238262117,\n",
       " 0.00037959442124702036,\n",
       " 0.00037848667125217617,\n",
       " 0.00037677600630559027,\n",
       " 0.00037565684760920703,\n",
       " 0.00037424080073833466,\n",
       " 0.0003726115683093667,\n",
       " 0.00037149296258576214,\n",
       " 0.00036982816527597606,\n",
       " 0.0003686544660013169,\n",
       " 0.00036706915125250816,\n",
       " 0.00036589684896171093,\n",
       " 0.0003644825192168355,\n",
       " 0.0003630520077422261,\n",
       " 0.00036188095691613853,\n",
       " 0.0003604006487876177,\n",
       " 0.00035913128522224724,\n",
       " 0.00035790467518381774,\n",
       " 0.0003564903454389423,\n",
       " 0.00035523995757102966,\n",
       " 0.00035405217204242945,\n",
       " 0.0003526397340465337,\n",
       " 0.00035151655902154744,\n",
       " 0.0003503512416500598,\n",
       " 0.00034890297683887184,\n",
       " 0.0003477545396890491,\n",
       " 0.00034654050250537694,\n",
       " 0.000345195789122954,\n",
       " 0.00034405430778861046,\n",
       " 0.0003429306671023369,\n",
       " 0.00034157626214437187,\n",
       " 0.00034048184170387685,\n",
       " 0.0003394760424271226,\n",
       " 0.00033816395443864167,\n",
       " 0.0003368791367392987,\n",
       " 0.0003357750829309225,\n",
       " 0.00033464119769632816,\n",
       " 0.0003333911008667201,\n",
       " 0.0003322871634736657,\n",
       " 0.0003311594482511282,\n",
       " 0.0003300272219348699,\n",
       " 0.00032883594394661486,\n",
       " 0.0003277271753177047,\n",
       " 0.00032661695149727166,\n",
       " 0.0003255866758991033,\n",
       " 0.00032445270335301757,\n",
       " 0.0003233923634979874,\n",
       " 0.0003222718369215727,\n",
       " 0.00032114595524035394,\n",
       " 0.00032008852576836944,\n",
       " 0.0003189789713360369,\n",
       " 0.0003179390332661569,\n",
       " 0.00031700992258265615,\n",
       " 0.0003162643115501851,\n",
       " 0.0003148356336168945,\n",
       " 0.0003138048341497779,\n",
       " 0.0003129069518763572,\n",
       " 0.000311703683109954,\n",
       " 0.0003107987577095628,\n",
       " 0.0003099488967563957,\n",
       " 0.00030864952714182436,\n",
       " 0.0003079938469454646,\n",
       " 0.0003067265497520566,\n",
       " 0.00030575713026337326,\n",
       " 0.0003047639911528677,\n",
       " 0.00030361436074599624,\n",
       " 0.00030274270102381706,\n",
       " 0.00030161309405229986,\n",
       " 0.0003007193736266345,\n",
       " 0.00029973630444146693,\n",
       " 0.00029867017292417586,\n",
       " 0.00029782301862724125,\n",
       " 0.00029672932578250766,\n",
       " 0.00029579162946902215,\n",
       " 0.00029493155307136476,\n",
       " 0.0002938314573839307,\n",
       " 0.0002929871261585504,\n",
       " 0.00029204500606283545,\n",
       " 0.0002909922623075545,\n",
       " 0.0002902593114413321,\n",
       " 0.000289280666038394,\n",
       " 0.00028823374304920435,\n",
       " 0.0002874418569263071,\n",
       " 0.000286420457996428,\n",
       " 0.0002855480706784874,\n",
       " 0.00028469492099247873,\n",
       " 0.0002837104257196188,\n",
       " 0.00028283498249948025,\n",
       " 0.0002820699301082641,\n",
       " 0.0002811424492392689,\n",
       " 0.00028018266311846673,\n",
       " 0.00027933166711591184,\n",
       " 0.0002784699900075793,\n",
       " 0.0002775847679004073,\n",
       " 0.00027666566893458366,\n",
       " 0.0002758497721515596,\n",
       " 0.0002751195279415697,\n",
       " 0.000274225341854617,\n",
       " 0.0002733460278250277,\n",
       " 0.00027242713258601725,\n",
       " 0.0002716978779062629,\n",
       " 0.00027087514172308147,\n",
       " 0.00026997309760190547,\n",
       " 0.0002691000991035253,\n",
       " 0.000268386589596048,\n",
       " 0.00026748678646981716,\n",
       " 0.00026664865436032414,\n",
       " 0.0002658322046045214,\n",
       " 0.0002650197420734912,\n",
       " 0.0002642370236571878,\n",
       " 0.0002634562843013555,\n",
       " 0.0002628561051096767,\n",
       " 0.00026198234991170466,\n",
       " 0.0002611060917843133,\n",
       " 0.0002603279135655612,\n",
       " 0.00025961623759940267,\n",
       " 0.00025873244157992303,\n",
       " 0.0002579652064014226,\n",
       " 0.0002572973317001015,\n",
       " 0.00025648591690696776,\n",
       " 0.0002556413528509438,\n",
       " 0.00025496562011539936,\n",
       " 0.0002542930596973747,\n",
       " 0.0002534448867663741,\n",
       " 0.00025266289594583213,\n",
       " 0.00025194688350893557,\n",
       " 0.00025117152836173773,\n",
       " 0.00025041395565494895,\n",
       " 0.00024967940407805145,\n",
       " 0.00024898358969949186,\n",
       " 0.0002483446442056447,\n",
       " 0.00024753468460403383,\n",
       " 0.00024678008048795164,\n",
       " 0.00024607268278487027,\n",
       " 0.0002454007917549461,\n",
       " 0.00024479717831127346,\n",
       " 0.000243943024543114,\n",
       " 0.0002432326873531565,\n",
       " 0.00024268723791465163,\n",
       " 0.0002419515367364511,\n",
       " 0.00024123558250721544,\n",
       " 0.0002404807455604896,\n",
       " 0.0002398654614808038,\n",
       " 0.00023914668418001384,\n",
       " 0.00023841871006879956,\n",
       " 0.00023779364710208029,\n",
       " 0.00023728919040877372,\n",
       " 0.00023642195446882397,\n",
       " 0.0002357128105359152,\n",
       " 0.0002351467264816165,\n",
       " 0.00023443553072866052,\n",
       " 0.00023375492310151458,\n",
       " 0.0002330882562091574,\n",
       " 0.0002324445522390306,\n",
       " 0.0002317944454262033,\n",
       " 0.00023110239999368787,\n",
       " 0.00023047100694384426,\n",
       " 0.00022984335373621434,\n",
       " 0.00022923956566955894,\n",
       " 0.0002286923845531419,\n",
       " 0.0002280607441207394,\n",
       " 0.0002273284044349566,\n",
       " 0.0002267323579872027,\n",
       " 0.00022616679780185223,\n",
       " 0.00022540670761372894,\n",
       " 0.00022481322230305523,\n",
       " 0.00022422196343541145,\n",
       " 0.00022364857431966811,\n",
       " 0.00022295494272839278,\n",
       " 0.00022236899530980736,\n",
       " 0.0002218644367530942,\n",
       " 0.00022128387354314327,\n",
       " 0.00022052529675420374,\n",
       " 0.00022006213839631528,\n",
       " 0.00021958402066957206,\n",
       " 0.00021879981795791537,\n",
       " 0.00021837737585883588,\n",
       " 0.00021769717568531632,\n",
       " 0.00021705271501559764,\n",
       " 0.00021652398572769016,\n",
       " 0.0002158372080884874,\n",
       " 0.00021532857499551028,\n",
       " 0.00021465936151798815,\n",
       " 0.00021410432236734778,\n",
       " 0.00021367601584643126,\n",
       " 0.00021292781457304955,\n",
       " 0.0002125287865055725,\n",
       " 0.00021192821441218257,\n",
       " 0.00021127496438566595,\n",
       " 0.00021080696024000645,\n",
       " 0.00021010467025917023,\n",
       " 0.00020967454474885017,\n",
       " 0.00020897308422718197,\n",
       " 0.00020860483346041292,\n",
       " 0.00020802205835934728,\n",
       " 0.00020734131976496428,\n",
       " 0.00020692881662398577,\n",
       " 0.00020624959142878652,\n",
       " 0.00020579749252647161,\n",
       " 0.0002051771734841168,\n",
       " 0.00020465109264478087,\n",
       " 0.0002041544794337824,\n",
       " 0.00020353800209704787,\n",
       " 0.0002030700707109645,\n",
       " 0.00020259740995243192,\n",
       " 0.0002019234816543758,\n",
       " 0.00020150147611275315,\n",
       " 0.0002009541931329295,\n",
       " 0.00020034647604916245,\n",
       " 0.00019992270972579718,\n",
       " 0.0001994101476157084,\n",
       " 0.00019877632439602166,\n",
       " 0.00019834708655253053,\n",
       " 0.00019785964104812592,\n",
       " 0.0001972983154701069,\n",
       " 0.00019677920499816537,\n",
       " 0.00019636120123323053,\n",
       " 0.00019578430510591716,\n",
       " 0.0001953194587258622,\n",
       " 0.00019498735491652042,\n",
       " 0.0001942572562256828,\n",
       " 0.00019395386334508657,\n",
       " 0.0001934729516506195,\n",
       " 0.00019283965229988098,\n",
       " 0.00019253959180787206,\n",
       " 0.00019182608230039477,\n",
       " 0.00019146532576996833,\n",
       " 0.0001908749109134078,\n",
       " 0.00019045233784709126,\n",
       " 0.00019000475003849715,\n",
       " 0.0001894243323476985,\n",
       " 0.00018905597971752286,\n",
       " 0.00018848826584871858,\n",
       " 0.0001880106283351779,\n",
       " 0.00018760056991595775,\n",
       " 0.0001870672422228381,\n",
       " 0.00018665568495634943,\n",
       " 0.0001861595083028078,\n",
       " 0.00018565698701422662,\n",
       " 0.00018523300241213292,\n",
       " 0.00018472473311703652,\n",
       " 0.0001842745259637013,\n",
       " 0.00018383190035820007,\n",
       " 0.0001833674032241106,\n",
       " 0.00018289056606590748,\n",
       " 0.00018243130762130022,\n",
       " 0.00018200937483925372,\n",
       " 0.00018159100727643818,\n",
       " 0.00018132966943085194,\n",
       " 0.00018077513959724456,\n",
       " 0.00018027429177891463,\n",
       " 0.00017985627346206456,\n",
       " 0.0001794640556909144,\n",
       " 0.00017891051538754255,\n",
       " 0.0001785031781764701,\n",
       " 0.00017820387438405305,\n",
       " 0.00017768637917470187,\n",
       " 0.00017720409960020334,\n",
       " 0.00017676908464636654,\n",
       " 0.0001763694453984499,\n",
       " 0.00017592763470020145,\n",
       " 0.00017547734023537487,\n",
       " 0.00017506328003946692,\n",
       " 0.00017475707863923162,\n",
       " 0.000174302767845802,\n",
       " 0.000173838299815543,\n",
       " 0.00017336552264168859,\n",
       " 0.00017301314801443368,\n",
       " 0.0001726251357467845,\n",
       " 0.00017222703900188208,\n",
       " 0.00017173936066683382,\n",
       " 0.0001713913370622322,\n",
       " 0.00017100245167966932,\n",
       " 0.00017057031800504774,\n",
       " 0.00017011311138048768,\n",
       " 0.00016976396727841347,\n",
       " 0.0001694312086328864,\n",
       " 0.00016893305291887373,\n",
       " 0.00016852404223755002,\n",
       " 0.00016816538118291646,\n",
       " 0.00016778167628217489,\n",
       " 0.00016731012146919966,\n",
       " 0.00016691851487848908,\n",
       " 0.00016654377395752817,\n",
       " 0.0001661770511418581,\n",
       " 0.00016574801702518016,\n",
       " 0.00016533832240384072,\n",
       " 0.00016497184697072953,\n",
       " 0.00016464863438159227,\n",
       " 0.00016440699982922524,\n",
       " 0.00016385082562919706,\n",
       " 0.0001634365617064759,\n",
       " 0.00016313709784299135,\n",
       " 0.00016271091590169817,\n",
       " 0.00016228144522756338,\n",
       " 0.00016193666670005769,\n",
       " 0.00016158159996848553,\n",
       " 0.00016123805835377425,\n",
       " 0.00016079124179668725,\n",
       " 0.00016040849732235074,\n",
       " 0.00016006057558115572,\n",
       " 0.0001596880319993943,\n",
       " 0.00015932087262626737,\n",
       " 0.00015897881530690938,\n",
       " 0.00015868352784309536,\n",
       " 0.00015834941586945206,\n",
       " 0.00015786083531565964,\n",
       " 0.0001575188071001321,\n",
       " 0.00015724498371127993,\n",
       " 0.00015682638331782073,\n",
       " 0.00015640539641026407,\n",
       " 0.00015615047595929354,\n",
       " 0.00015573918062727898,\n",
       " 0.00015534620615653694,\n",
       " 0.00015498303400818259,\n",
       " 0.00015468108176719397,\n",
       " 0.00015429231279995292,\n",
       " 0.00015392409113701433,\n",
       " 0.00015356088988482952,\n",
       " 0.00015328482550103217,\n",
       " 0.00015300717495847493,\n",
       " 0.00015261225053109229,\n",
       " 0.0001521979720564559,\n",
       " 0.0001519471115898341,\n",
       " 0.00015161714691203088,\n",
       " 0.0001511986629338935,\n",
       " 0.00015088373038452119,\n",
       " 0.00015063797764014453,\n",
       " 0.00015017921396065503,\n",
       " 0.00014983104483690113,\n",
       " 0.00014954920334275812,\n",
       " 0.000149158135172911,\n",
       " 0.0001488490670453757,\n",
       " 0.00014855556946713477,\n",
       " 0.00014815095346421003,\n",
       " 0.00014784505765419453,\n",
       " 0.00014760560588911176,\n",
       " 0.00014718757302034646,\n",
       " 0.00014683078916277736,\n",
       " 0.00014654858387075365,\n",
       " 0.00014618533896282315,\n",
       " 0.00014585861936211586,\n",
       " 0.0001455689052818343,\n",
       " 0.00014530663611367345,\n",
       " 0.00014512406778521836,\n",
       " 0.00014463016123045236,\n",
       " 0.00014435697812587023,\n",
       " 0.00014415256737265736,\n",
       " 0.00014370097778737545,\n",
       " 0.00014350553101394325,\n",
       " 0.00014324056974146515,\n",
       " 0.00014276795263867825,\n",
       " 0.0001426427625119686,\n",
       " 0.00014216906856745481,\n",
       " 0.0001419510954292491,\n",
       " 0.0001416613085893914,\n",
       " 0.00014125689631327987,\n",
       " 0.00014105696754995733,\n",
       " 0.00014062660920899361,\n",
       " 0.00014047643344383687,\n",
       " 0.0001400156324962154,\n",
       " 0.00013982052041683346,\n",
       " 0.0001394493883708492,\n",
       " 0.00013916136231273413,\n",
       " 0.0001389127573929727,\n",
       " 0.00013853282143827528,\n",
       " 0.00013833941193297505,\n",
       " 0.00013798841973766685,\n",
       " 0.0001376913278363645,\n",
       " 0.00013743732415605336,\n",
       " 0.00013706956815440208,\n",
       " 0.00013684149598702788,\n",
       " 0.00013655016664415598,\n",
       " 0.0001362121693091467,\n",
       " 0.0001359642337774858,\n",
       " 0.0001356346474494785,\n",
       " 0.0001353723055217415,\n",
       " 0.00013513874728232622,\n",
       " 0.00013477129687089473,\n",
       " 0.0001345330965705216,\n",
       " 0.0001343023614026606,\n",
       " 0.00013395980931818485,\n",
       " 0.000133672816446051,\n",
       " 0.00013348193897400051,\n",
       " 0.00013309273344930261,\n",
       " 0.00013287436740938574,\n",
       " 0.00013264316658023745,\n",
       " 0.00013227693852968514,\n",
       " 0.00013207309530116618,\n",
       " 0.00013188342563807964,\n",
       " 0.00013145631237421185,\n",
       " 0.00013139779912307858,\n",
       " 0.00013098899216856807,\n",
       " 0.00013071848661638796,\n",
       " 0.0001304642646573484,\n",
       " 0.00013011417468078434,\n",
       " 0.00012994171993341297,\n",
       " 0.00012957431317772716,\n",
       " 0.00012937706196680665,\n",
       " 0.00012910620716866106,\n",
       " 0.00012878759298473597,\n",
       " 0.00012859137495979667,\n",
       " 0.000128283238154836,\n",
       " 0.00012804337893612683,\n",
       " 0.00012780250108335167,\n",
       " 0.000127461229567416,\n",
       " 0.0001272465306101367,\n",
       " 0.00012696375779341906,\n",
       " 0.00012667365081142634,\n",
       " 0.00012643371883314103,\n",
       " 0.00012617722677532583,\n",
       " 0.00012590094411280006,\n",
       " 0.00012564301141537726,\n",
       " 0.00012541904288809747,\n",
       " 0.0001252045767614618,\n",
       " 0.0001249652705155313,\n",
       " 0.00012467689521145076,\n",
       " 0.00012439470447134227,\n",
       " 0.000124173064250499,\n",
       " 0.00012393310316838324,\n",
       " 0.00012364183203317225,\n",
       " 0.0001234092196682468,\n",
       " 0.00012317243090365082,\n",
       " 0.00012301582319196314,\n",
       " 0.00012267901911400259,\n",
       " 0.0001224227889906615,\n",
       " 0.0001221792190335691,\n",
       " 0.00012192445137770846,\n",
       " 0.00012167536624474451,\n",
       " 0.00012152053386671469,\n",
       " 0.00012130852701375261,\n",
       " 0.00012098912702640519,\n",
       " 0.00012072138633811846,\n",
       " 0.00012056657578796148,\n",
       " 0.00012031791993649676,\n",
       " 0.00012001761933788657,\n",
       " 0.00011980537237832323,\n",
       " 0.00011959625408053398,\n",
       " 0.00011931770131923258,\n",
       " 0.00011906997679034248,\n",
       " 0.00011888964218087494,\n",
       " 0.00011867950524901971,\n",
       " 0.00011842270760098472,\n",
       " 0.0001181681509478949,\n",
       " 0.00011796163016697392,\n",
       " 0.00011769236880354583,\n",
       " 0.00011748011456802487,\n",
       " 0.00011727894889190793,\n",
       " 0.00011701542098307982,\n",
       " 0.00011677000293275341,\n",
       " 0.00011652799003059044,\n",
       " 0.00011631339293671772,\n",
       " 0.00011608475324464962,\n",
       " 0.00011586104665184394,\n",
       " 0.0001156440339400433,\n",
       " 0.00011543036816874519,\n",
       " 0.00011531620839377865,\n",
       " 0.00011504726717248559,\n",
       " 0.00011477004591142759,\n",
       " 0.00011453422484919429,\n",
       " 0.00011437197827035561,\n",
       " 0.00011413711035856977,\n",
       " 0.0001139097148552537,\n",
       " 0.00011365182581357658,\n",
       " 0.00011343985534040257,\n",
       " 0.0001132054312620312,\n",
       " 0.00011299722245894372,\n",
       " 0.00011277341400273144,\n",
       " 0.00011256118887104094,\n",
       " 0.00011236438149353489,\n",
       " 0.00011222242756048217,\n",
       " 0.00011211058154003695,\n",
       " 0.00011173092207172886,\n",
       " 0.00011155533866258338,\n",
       " 0.00011143636220367625,\n",
       " 0.00011108946637250483,\n",
       " 0.00011098672257503495,\n",
       " 0.00011086621816502884,\n",
       " 0.0001104967959690839,\n",
       " 0.00011046996951336041,\n",
       " 0.00011007222201442346,\n",
       " 0.00010996885976055637,\n",
       " 0.00010968285641865805,\n",
       " 0.00010949480929411948,\n",
       " 0.00010933802695944905,\n",
       " 0.00010904140799539164,\n",
       " 0.00010891928104683757,\n",
       " 0.00010862585622817278,\n",
       " 0.0001084758187062107,\n",
       " 0.00010822114563779905,\n",
       " 0.00010803604527609423,\n",
       " 0.00010786149505292997,\n",
       " 0.00010760151781141758,\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36ee742a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.373678Z",
     "iopub.status.busy": "2023-12-02T16:46:06.373302Z",
     "iopub.status.idle": "2023-12-02T16:46:06.495029Z",
     "shell.execute_reply": "2023-12-02T16:46:06.494202Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.131652,
     "end_time": "2023-12-02T16:46:06.496814",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.365162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5735, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3601, grad_fn=<MeanBackward0>)\n",
      "tensor(7.7696, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0410, grad_fn=<MeanBackward0>)\n",
      "tensor(5.3624, grad_fn=<MeanBackward0>)\n",
      "tensor(8.2007, grad_fn=<MeanBackward0>)\n",
      "tensor(7.4288, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0443, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9201, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0870, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3388, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6505, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2653, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2492, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8631, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5678, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5633, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6594, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6528, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9504, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0098, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2867, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5415, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2388, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9456, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0282, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9980, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6725, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9429, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4912, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7391, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5812, grad_fn=<MeanBackward0>)\n",
      "tensor(8.4370, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0540, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8217, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1904, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2301, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2198, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7545, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8780, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6026, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2327, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7438, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1095, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3182, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3531, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1542, grad_fn=<MeanBackward0>)\n",
      "tensor(7.7566, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2247, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5396, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8740, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2081, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8959, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4439, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6222, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7298, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2266, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8852, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2552, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9561, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3036, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9104, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3177, grad_fn=<MeanBackward0>)\n",
      "tensor(8.3065, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8734, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0958, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7339, grad_fn=<MeanBackward0>)\n",
      "tensor(7.1299, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5601, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8854, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7537, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3909, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5866, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1051, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2454, grad_fn=<MeanBackward0>)\n",
      "tensor(7.4197, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1848, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5539, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7574, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4846, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1428, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8540, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6716, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0653, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9824, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9458, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1875, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3613, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6898, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7734, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2144, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0797, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2769, grad_fn=<MeanBackward0>)\n",
      "tensor(5.3129, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7674, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7974, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5840, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2385, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2033, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9402, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    T = 50      # Input sequence length\n",
    "    C = 20      # Number of classes (including blank)\n",
    "    N = 16      # Batch size\n",
    "    S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "    S_min = 10  # Minimum target length, for demonstration purposes\n",
    "    # Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "    input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "    # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "    target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "    input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "    target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "    ctc_loss = nn.CTCLoss()\n",
    "    loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c6f606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.512150Z",
     "iopub.status.busy": "2023-12-02T16:46:06.511673Z",
     "iopub.status.idle": "2023-12-02T16:46:06.520208Z",
     "shell.execute_reply": "2023-12-02T16:46:06.519394Z"
    },
    "papermill": {
     "duration": 0.01823,
     "end_time": "2023-12-02T16:46:06.522039",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.503809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 31])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [23],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 2],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [14],\n",
       "        [ 2],\n",
       "        [26],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = out[:,5:5+1,:]\n",
    "print(test.shape)\n",
    "decode_pred(test,None)\n",
    "test.argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f625378",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.537840Z",
     "iopub.status.busy": "2023-12-02T16:46:06.537275Z",
     "iopub.status.idle": "2023-12-02T16:46:06.543951Z",
     "shell.execute_reply": "2023-12-02T16:46:06.543251Z"
    },
    "papermill": {
     "duration": 0.016544,
     "end_time": "2023-12-02T16:46:06.545662",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.529118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 23,  2, 14,  2, 26])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "679c149f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.562762Z",
     "iopub.status.busy": "2023-12-02T16:46:06.561915Z",
     "iopub.status.idle": "2023-12-02T16:46:06.568917Z",
     "shell.execute_reply": "2023-12-02T16:46:06.567744Z"
    },
    "papermill": {
     "duration": 0.018137,
     "end_time": "2023-12-02T16:46:06.571050",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.552913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 48])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,dim=2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bcc7487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:46:06.586682Z",
     "iopub.status.busy": "2023-12-02T16:46:06.586246Z",
     "iopub.status.idle": "2023-12-02T16:46:06.591489Z",
     "shell.execute_reply": "2023-12-02T16:46:06.590096Z"
    },
    "papermill": {
     "duration": 0.015893,
     "end_time": "2023-12-02T16:46:06.594029",
     "exception": false,
     "start_time": "2023-12-02T16:46:06.578136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git remote add origin https://github.com/Mohamad-Atif1/CTC_loss_PyTorch.git\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1515974,
     "sourceId": 2503457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 697.438673,
   "end_time": "2023-12-02T16:46:07.624779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T16:34:30.186106",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
