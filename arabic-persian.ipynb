{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949155c0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:20.547670Z",
     "iopub.status.busy": "2023-12-02T16:18:20.547236Z",
     "iopub.status.idle": "2023-12-02T16:18:26.042469Z",
     "shell.execute_reply": "2023-12-02T16:18:26.041211Z"
    },
    "papermill": {
     "duration": 5.509144,
     "end_time": "2023-12-02T16:18:26.045147",
     "exception": false,
     "start_time": "2023-12-02T16:18:20.536003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "from torch import optim as opt\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing \n",
    "from torchvision import transforms\n",
    "import imageio as iio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a2bc28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.060246Z",
     "iopub.status.busy": "2023-12-02T16:18:26.059606Z",
     "iopub.status.idle": "2023-12-02T16:18:26.064896Z",
     "shell.execute_reply": "2023-12-02T16:18:26.063559Z"
    },
    "papermill": {
     "duration": 0.015276,
     "end_time": "2023-12-02T16:18:26.067151",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.051875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 48\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c3077c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.081832Z",
     "iopub.status.busy": "2023-12-02T16:18:26.081435Z",
     "iopub.status.idle": "2023-12-02T16:18:26.626007Z",
     "shell.execute_reply": "2023-12-02T16:18:26.625148Z"
    },
    "papermill": {
     "duration": 0.554861,
     "end_time": "2023-12-02T16:18:26.628451",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.073590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['Amin','Farzad','Maziar','Mehrdad','Sina','Soheil','Vahid']\n",
    "name_file = {name:[] for name in names}\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/arabicpersian-handwritten-cities-for-postal-apps/scan splited/scan splited'):\n",
    "    filenames = sorted(filenames) # i want it to be on the same order\n",
    "    for filename in filenames:\n",
    "        name = dirname[89:]\n",
    "        name_file[name].append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a9d6f",
   "metadata": {
    "papermill": {
     "duration": 0.005877,
     "end_time": "2023-12-02T16:18:26.640528",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.634651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# I just want to take a subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f09add8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.655869Z",
     "iopub.status.busy": "2023-12-02T16:18:26.655243Z",
     "iopub.status.idle": "2023-12-02T16:18:26.661661Z",
     "shell.execute_reply": "2023-12-02T16:18:26.660616Z"
    },
    "papermill": {
     "duration": 0.017043,
     "end_time": "2023-12-02T16:18:26.664409",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.647366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "alphabit = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويئ\"\n",
    "num_output = len(alphabit)\n",
    "alphabit = [a for a in alphabit]\n",
    "print(num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa8872a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.679191Z",
     "iopub.status.busy": "2023-12-02T16:18:26.678792Z",
     "iopub.status.idle": "2023-12-02T16:18:26.685142Z",
     "shell.execute_reply": "2023-12-02T16:18:26.683984Z"
    },
    "papermill": {
     "duration": 0.016571,
     "end_time": "2023-12-02T16:18:26.687350",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.670779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_words(targets):\n",
    "    \"\"\"\n",
    "    Padding words to make all of them on the same size\n",
    "    \"\"\"\n",
    "    targets_new = []\n",
    "    for target in targets:\n",
    "        pad = 6-len(target)\n",
    "        targets_new.append(np.concatenate((np.ones(pad),target),axis=0).astype(np.longlong))\n",
    "        \n",
    "        \n",
    "    return targets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd70552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.702485Z",
     "iopub.status.busy": "2023-12-02T16:18:26.701772Z",
     "iopub.status.idle": "2023-12-02T16:18:26.720140Z",
     "shell.execute_reply": "2023-12-02T16:18:26.719005Z"
    },
    "papermill": {
     "duration": 0.028727,
     "end_time": "2023-12-02T16:18:26.722707",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.693980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = (\" خيابان ميدان نمين ديلم مهران كاشان برحوار نائين البرز يزد تبريز سيريك\") # only these words will be considerd\n",
    "words = words*4 # four persons wrote these words\n",
    "words = words.split(' ')\n",
    "words.__delitem__(0) # first element is just empty\n",
    "\n",
    "\n",
    "imgs = []\n",
    "for name,files in name_file.items():\n",
    "    if  name.__eq__('Maziar') or name.__eq__('Mehrdad') or name.__eq__('Sina'):\n",
    "        continue\n",
    "    for i,file in enumerate(files):\n",
    "        if i == 12:\n",
    "            break\n",
    "        imgs.append(file)\n",
    "    \n",
    "\n",
    "targets = [[w for w in word] for word in words]\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "lbl_enc.fit(alphabit)\n",
    "targets_enc = [lbl_enc.transform(word)+1 for word in targets]\n",
    "targets_enc = pad_words(targets_enc)\n",
    "dataset = {'imgs':imgs, \"labels\":targets_enc}\n",
    "df = pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e4566",
   "metadata": {
    "papermill": {
     "duration": 0.005913,
     "end_time": "2023-12-02T16:18:26.734946",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.729033",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2016741b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.750068Z",
     "iopub.status.busy": "2023-12-02T16:18:26.749642Z",
     "iopub.status.idle": "2023-12-02T16:18:26.755856Z",
     "shell.execute_reply": "2023-12-02T16:18:26.754995Z"
    },
    "papermill": {
     "duration": 0.016126,
     "end_time": "2023-12-02T16:18:26.757810",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.741684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,trans=None):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = Image.open(self.df['imgs'][idx]).convert('RGB')\n",
    "        if trans:\n",
    "            x = trans(x)\n",
    "        y = self.df['labels'][idx] # +1 i have already add one in the above cell \n",
    "        return (x,y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3300e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.772550Z",
     "iopub.status.busy": "2023-12-02T16:18:26.771604Z",
     "iopub.status.idle": "2023-12-02T16:18:26.775832Z",
     "shell.execute_reply": "2023-12-02T16:18:26.774865Z"
    },
    "papermill": {
     "duration": 0.013845,
     "end_time": "2023-12-02T16:18:26.778070",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.764225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std = torch.tensor([0.0603, 0.0606, 0.0347])\n",
    "# mean = torch.tensor([[0.8753, 0.8924, 0.9244]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ef75f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.794154Z",
     "iopub.status.busy": "2023-12-02T16:18:26.793356Z",
     "iopub.status.idle": "2023-12-02T16:18:26.800612Z",
     "shell.execute_reply": "2023-12-02T16:18:26.799426Z"
    },
    "papermill": {
     "duration": 0.019434,
     "end_time": "2023-12-02T16:18:26.803819",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.784385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(20,80)),\n",
    "    transforms.Normalize(mean=(0.8753,0.8924,0.9244),std=(0.0603,0.0606,0.0347))\n",
    "                           ])\n",
    "all_imgs = []\n",
    "dataset = Mydataset(df,trans)\n",
    "\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=bs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e8e93a",
   "metadata": {
    "papermill": {
     "duration": 0.006851,
     "end_time": "2023-12-02T16:18:26.818696",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.811845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b7cc9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.834560Z",
     "iopub.status.busy": "2023-12-02T16:18:26.833842Z",
     "iopub.status.idle": "2023-12-02T16:18:26.889056Z",
     "shell.execute_reply": "2023-12-02T16:18:26.887895Z"
    },
    "papermill": {
     "duration": 0.066538,
     "end_time": "2023-12-02T16:18:26.891567",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.825029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ح'], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  torch.tensor([ [ [1,2,3],[5,6,4] ],[[1,1,1],[2,2,2]] ])\n",
    "aaa = torch.argmax(test,dim=1)  \n",
    "# lbl_enc.inverse_transform\n",
    "a = [ t.shape for t in aaa]\n",
    "aaa.shape\n",
    "\n",
    "lbl_enc.inverse_transform(np.array([6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58433c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.909869Z",
     "iopub.status.busy": "2023-12-02T16:18:26.909419Z",
     "iopub.status.idle": "2023-12-02T16:18:26.918745Z",
     "shell.execute_reply": "2023-12-02T16:18:26.917599Z"
    },
    "papermill": {
     "duration": 0.021874,
     "end_time": "2023-12-02T16:18:26.920988",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.899114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def decode_pred(y_pred,targets):\n",
    "    \"\"\"\n",
    "    convert numbers to its corresponding characters \n",
    "    0 -> blank\n",
    "    1 -> padding\n",
    "    y_pred : output of the model [T,bs,num_classes]\n",
    "    targets : the ground truth [bs,num of characters]\n",
    "    \"\"\"\n",
    "    y_pred = torch.argmax(y_pred,dim=2)  \n",
    "    # now our tensor is [T,bs] , in each time stamp there is the charecter with the highest probablity \n",
    "    y_pred = y_pred.permute(1,0) # [bs,T]\n",
    "    labels = [decode_word(word) for word in y_pred]\n",
    "    \n",
    "    # if 0 then its blank , replace it with ?\n",
    "    return labels\n",
    "    \n",
    "def decode_word(word):\n",
    "    \"\"\"\n",
    "    covert numbers to words\n",
    "    words shape: [T] the highest probabilty in each time stamp\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    for character in word:\n",
    "        character -= 2 \n",
    "        if character.item() == -2 :\n",
    "            characters.append(\"?\")\n",
    "        elif character.item() == -1:\n",
    "            characters.append(\"P\")\n",
    "        else:\n",
    "            characters.append(lbl_enc.inverse_transform([character]))        \n",
    "    \n",
    "    return characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b66149",
   "metadata": {
    "papermill": {
     "duration": 0.006739,
     "end_time": "2023-12-02T16:18:26.934530",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.927791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d69ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:26.953061Z",
     "iopub.status.busy": "2023-12-02T16:18:26.952322Z",
     "iopub.status.idle": "2023-12-02T16:18:26.967798Z",
     "shell.execute_reply": "2023-12-02T16:18:26.966900Z"
    },
    "papermill": {
     "duration": 0.027538,
     "end_time": "2023-12-02T16:18:26.970264",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.942726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_map = torch.tensor([48, 84, 5, 20]) # bs,c,h,w\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,12,3,2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(12,36,3,2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(36,84,3,1,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv2(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv3(F.relu(x))\n",
    "        return x\n",
    "    \n",
    "class MyRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_layers,bi):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers        \n",
    "        self.bi = bi\n",
    "        self.gru = nn.GRU(input_size,hidden_size,num_layers,bidirectional=bi,batch_first=True)\n",
    "        self.linear1 = nn.Linear(hidden_size,hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size,num_output+2) # +1 for the blank ctc\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        D = 2 if self.bi else 1 \n",
    "        h0 = torch.zeros(D*self.num_layers,x.size(0),self.hidden_size)\n",
    "        out,hn = self.gru(x,h0)\n",
    "#         print(out.shape)\n",
    "        out = self.linear1(F.relu(out))\n",
    "        out = self.linear2(out)\n",
    "        out = F.log_softmax(out,dim=2)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "# class denseLayer(nn.Module):\n",
    "#     def __init__\n",
    "    \n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_size,num_layers,bi):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers  \n",
    "        self.bi = bi\n",
    "        self.cnn = MyCNN()\n",
    "        self.rnn = MyRNN(feature_map[1]*feature_map[2],hidden_size,num_layers,bi)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "#         print(x.shape) # --> (bs,c,h,w)\n",
    "        x = x.view(-1,x.shape[3],x.shape[2]*x.shape[1]) # --> (bs,w,h*c)\n",
    "        \n",
    "        # i will assume that num of channels is the time_stamps \n",
    "        # i've changed my mind :) , w = time_stamps\n",
    "        # for rnn , we need (time_stamps,bs,featuers)\n",
    "        \n",
    "        x = x.permute(1,0,2) \n",
    "#         print(x.shape)\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504d3f4",
   "metadata": {
    "papermill": {
     "duration": 0.006265,
     "end_time": "2023-12-02T16:18:26.983155",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.976890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a07102",
   "metadata": {
    "papermill": {
     "duration": 0.005985,
     "end_time": "2023-12-02T16:18:26.995513",
     "exception": false,
     "start_time": "2023-12-02T16:18:26.989528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce925990",
   "metadata": {
    "papermill": {
     "duration": 0.005848,
     "end_time": "2023-12-02T16:18:27.007626",
     "exception": false,
     "start_time": "2023-12-02T16:18:27.001778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7f1e28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:27.022028Z",
     "iopub.status.busy": "2023-12-02T16:18:27.021598Z",
     "iopub.status.idle": "2023-12-02T16:18:29.543003Z",
     "shell.execute_reply": "2023-12-02T16:18:29.541730Z"
    },
    "papermill": {
     "duration": 2.532485,
     "end_time": "2023-12-02T16:18:29.546327",
     "exception": false,
     "start_time": "2023-12-02T16:18:27.013842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loss_fn =  nn.CTCLoss(blank=0)\n",
    "model = MyModel(50,1,False)\n",
    "lr = 1e-3\n",
    "optim = opt.Adam(model.parameters(),lr=lr) \n",
    "\n",
    "batch = next(iter(train_loader))       \n",
    "train_loss = []\n",
    "for epoch in range (20):\n",
    "    losses = 0\n",
    "    for batch in train_loader:\n",
    "        x,y = batch[0],batch[1]\n",
    "        out = model(batch[0])\n",
    "        input_lengths = torch.full(size=(x.shape[0],), fill_value=out.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(x.shape[0],), fill_value=batch[1].size(1), dtype=torch.long)\n",
    "        optim.zero_grad()\n",
    "        loss = loss_fn(out,batch[1],input_lengths,target_lengths)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses += loss.item()\n",
    "        \n",
    "    train_loss.append(losses/len(train_loader))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa6d76d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:29.561341Z",
     "iopub.status.busy": "2023-12-02T16:18:29.560919Z",
     "iopub.status.idle": "2023-12-02T16:18:29.569533Z",
     "shell.execute_reply": "2023-12-02T16:18:29.568361Z"
    },
    "papermill": {
     "duration": 0.019384,
     "end_time": "2023-12-02T16:18:29.572514",
     "exception": false,
     "start_time": "2023-12-02T16:18:29.553130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.69526195526123,\n",
       " 8.62186050415039,\n",
       " 8.544053077697754,\n",
       " 8.45665168762207,\n",
       " 8.351344108581543,\n",
       " 8.21743392944336,\n",
       " 8.043932914733887,\n",
       " 7.814568042755127,\n",
       " 7.514636516571045,\n",
       " 7.130631923675537,\n",
       " 6.662744998931885,\n",
       " 6.129296779632568,\n",
       " 5.568948268890381,\n",
       " 5.024291515350342,\n",
       " 4.536387920379639,\n",
       " 4.125744819641113,\n",
       " 3.791290283203125,\n",
       " 3.5380771160125732,\n",
       " 3.368621587753296,\n",
       " 3.2758610248565674]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d305a2",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:29.587520Z",
     "iopub.status.busy": "2023-12-02T16:18:29.587135Z",
     "iopub.status.idle": "2023-12-02T16:18:29.731236Z",
     "shell.execute_reply": "2023-12-02T16:18:29.730025Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.155017,
     "end_time": "2023-12-02T16:18:29.734312",
     "exception": false,
     "start_time": "2023-12-02T16:18:29.579295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.0923, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9094, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1482, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5488, grad_fn=<MeanBackward0>)\n",
      "tensor(7.6069, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4448, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1566, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5373, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6793, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6901, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8133, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0626, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4212, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3961, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6635, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5537, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5617, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3032, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6341, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9120, grad_fn=<MeanBackward0>)\n",
      "tensor(7.4092, grad_fn=<MeanBackward0>)\n",
      "tensor(5.4615, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3853, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9251, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1947, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8468, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1095, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3022, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5495, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3185, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4829, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7608, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9028, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5342, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7304, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4172, grad_fn=<MeanBackward0>)\n",
      "tensor(7.1120, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4676, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0263, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6427, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6321, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1601, grad_fn=<MeanBackward0>)\n",
      "tensor(8.3163, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3216, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6412, grad_fn=<MeanBackward0>)\n",
      "tensor(5.3029, grad_fn=<MeanBackward0>)\n",
      "tensor(8.0757, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0013, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2740, grad_fn=<MeanBackward0>)\n",
      "tensor(7.0355, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5720, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7757, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9660, grad_fn=<MeanBackward0>)\n",
      "tensor(7.2631, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8831, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2288, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5450, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9799, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7833, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0646, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7401, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5121, grad_fn=<MeanBackward0>)\n",
      "tensor(6.6888, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8568, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1546, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0993, grad_fn=<MeanBackward0>)\n",
      "tensor(7.5623, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5579, grad_fn=<MeanBackward0>)\n",
      "tensor(6.9118, grad_fn=<MeanBackward0>)\n",
      "tensor(7.5994, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7617, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2666, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7527, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7203, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5216, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8242, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3770, grad_fn=<MeanBackward0>)\n",
      "tensor(5.5073, grad_fn=<MeanBackward0>)\n",
      "tensor(6.0630, grad_fn=<MeanBackward0>)\n",
      "tensor(7.1461, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3328, grad_fn=<MeanBackward0>)\n",
      "tensor(6.2099, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1933, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4387, grad_fn=<MeanBackward0>)\n",
      "tensor(6.3079, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4298, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5771, grad_fn=<MeanBackward0>)\n",
      "tensor(6.8284, grad_fn=<MeanBackward0>)\n",
      "tensor(5.8488, grad_fn=<MeanBackward0>)\n",
      "tensor(5.3608, grad_fn=<MeanBackward0>)\n",
      "tensor(6.7381, grad_fn=<MeanBackward0>)\n",
      "tensor(6.5466, grad_fn=<MeanBackward0>)\n",
      "tensor(5.6209, grad_fn=<MeanBackward0>)\n",
      "tensor(7.4880, grad_fn=<MeanBackward0>)\n",
      "tensor(6.1609, grad_fn=<MeanBackward0>)\n",
      "tensor(7.9295, grad_fn=<MeanBackward0>)\n",
      "tensor(5.9017, grad_fn=<MeanBackward0>)\n",
      "tensor(7.5712, grad_fn=<MeanBackward0>)\n",
      "tensor(5.7061, grad_fn=<MeanBackward0>)\n",
      "tensor(6.4054, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    T = 50      # Input sequence length\n",
    "    C = 20      # Number of classes (including blank)\n",
    "    N = 16      # Batch size\n",
    "    S = 30      # Target sequence length of longest target in batch (padding length)\n",
    "    S_min = 10  # Minimum target length, for demonstration purposes\n",
    "    # Initialize random batch of input vectors, for *size = (T,N,C)\n",
    "    input = torch.randn(T, N, C).log_softmax(2).detach().requires_grad_()\n",
    "    # Initialize random batch of targets (0 = blank, 1:C = classes)\n",
    "    target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
    "    input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
    "    target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
    "    ctc_loss = nn.CTCLoss()\n",
    "    loss = ctc_loss(input, target, input_lengths, target_lengths)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa46b91d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:29.749828Z",
     "iopub.status.busy": "2023-12-02T16:18:29.749432Z",
     "iopub.status.idle": "2023-12-02T16:18:29.778613Z",
     "shell.execute_reply": "2023-12-02T16:18:29.777413Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.039523,
     "end_time": "2023-12-02T16:18:29.780809",
     "exception": false,
     "start_time": "2023-12-02T16:18:29.741286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?'],\n",
       " ['?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?',\n",
       "  '?']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_pred(out,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "176a2f15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:29.797626Z",
     "iopub.status.busy": "2023-12-02T16:18:29.797232Z",
     "iopub.status.idle": "2023-12-02T16:18:29.804197Z",
     "shell.execute_reply": "2023-12-02T16:18:29.803177Z"
    },
    "papermill": {
     "duration": 0.017995,
     "end_time": "2023-12-02T16:18:29.806326",
     "exception": false,
     "start_time": "2023-12-02T16:18:29.788331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 48])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,dim=2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5f2c187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T16:18:29.823729Z",
     "iopub.status.busy": "2023-12-02T16:18:29.822944Z",
     "iopub.status.idle": "2023-12-02T16:18:29.827642Z",
     "shell.execute_reply": "2023-12-02T16:18:29.826626Z"
    },
    "papermill": {
     "duration": 0.015738,
     "end_time": "2023-12-02T16:18:29.829726",
     "exception": false,
     "start_time": "2023-12-02T16:18:29.813988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !git remote add origin https://github.com/Mohamad-Atif1/CTC_loss_PyTorch.git\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1515974,
     "sourceId": 2503457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.561911,
   "end_time": "2023-12-02T16:18:30.961986",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T16:18:17.400075",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
