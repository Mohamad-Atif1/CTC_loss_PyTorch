{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b49a94",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-02T18:35:54.748370Z",
     "iopub.status.busy": "2023-12-02T18:35:54.747951Z",
     "iopub.status.idle": "2023-12-02T18:36:00.746788Z",
     "shell.execute_reply": "2023-12-02T18:36:00.745673Z"
    },
    "papermill": {
     "duration": 6.015503,
     "end_time": "2023-12-02T18:36:00.750290",
     "exception": false,
     "start_time": "2023-12-02T18:35:54.734787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import torch\n",
    "from torch import optim as opt\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn import preprocessing \n",
    "from torchvision import transforms\n",
    "import imageio as iio\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ea7e7d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:00.769802Z",
     "iopub.status.busy": "2023-12-02T18:36:00.769242Z",
     "iopub.status.idle": "2023-12-02T18:36:00.773539Z",
     "shell.execute_reply": "2023-12-02T18:36:00.772697Z"
    },
    "papermill": {
     "duration": 0.016651,
     "end_time": "2023-12-02T18:36:00.775745",
     "exception": false,
     "start_time": "2023-12-02T18:36:00.759094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 48\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66df6fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:00.795086Z",
     "iopub.status.busy": "2023-12-02T18:36:00.794039Z",
     "iopub.status.idle": "2023-12-02T18:36:08.901410Z",
     "shell.execute_reply": "2023-12-02T18:36:08.900508Z"
    },
    "papermill": {
     "duration": 8.11985,
     "end_time": "2023-12-02T18:36:08.904087",
     "exception": false,
     "start_time": "2023-12-02T18:36:00.784237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "names = ['Amin','Farzad','Maziar','Mehrdad','Sina','Soheil','Vahid']\n",
    "name_file = {name:[] for name in names}\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/arabicpersian-handwritten-cities-for-postal-apps/scan splited/scan splited'):\n",
    "    filenames = sorted(filenames) # i want it to be on the same order\n",
    "    for filename in filenames:\n",
    "        name = dirname[89:]\n",
    "        name_file[name].append(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60b804",
   "metadata": {
    "papermill": {
     "duration": 0.008129,
     "end_time": "2023-12-02T18:36:08.920909",
     "exception": false,
     "start_time": "2023-12-02T18:36:08.912780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# I just want to take a subset of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d1382b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:08.939753Z",
     "iopub.status.busy": "2023-12-02T18:36:08.939114Z",
     "iopub.status.idle": "2023-12-02T18:36:08.945606Z",
     "shell.execute_reply": "2023-12-02T18:36:08.944484Z"
    },
    "papermill": {
     "duration": 0.018924,
     "end_time": "2023-12-02T18:36:08.948128",
     "exception": false,
     "start_time": "2023-12-02T18:36:08.929204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "alphabit = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويئ\"\n",
    "num_output = len(alphabit)\n",
    "alphabit = [a for a in alphabit]\n",
    "print(num_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b4c39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:08.967491Z",
     "iopub.status.busy": "2023-12-02T18:36:08.966680Z",
     "iopub.status.idle": "2023-12-02T18:36:08.972775Z",
     "shell.execute_reply": "2023-12-02T18:36:08.971989Z"
    },
    "papermill": {
     "duration": 0.018531,
     "end_time": "2023-12-02T18:36:08.975233",
     "exception": false,
     "start_time": "2023-12-02T18:36:08.956702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_words(targets):\n",
    "    \"\"\"\n",
    "    Padding words to make all of them on the same size\n",
    "    \"\"\"\n",
    "    targets_new = []\n",
    "    for target in targets:\n",
    "        pad = 6-len(target)\n",
    "        targets_new.append(np.concatenate((np.ones(pad),target),axis=0).astype(np.longlong))\n",
    "        \n",
    "        \n",
    "    return targets_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b8df35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:08.996427Z",
     "iopub.status.busy": "2023-12-02T18:36:08.996025Z",
     "iopub.status.idle": "2023-12-02T18:36:09.016461Z",
     "shell.execute_reply": "2023-12-02T18:36:09.015014Z"
    },
    "papermill": {
     "duration": 0.03337,
     "end_time": "2023-12-02T18:36:09.019360",
     "exception": false,
     "start_time": "2023-12-02T18:36:08.985990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = (\" خيابان ميدان نمين ديلم مهران كاشان برحوار نائين البرز يزد تبريز سيريك\") # only these words will be considerd\n",
    "words = words*4 # four persons wrote these words\n",
    "words = words.split(' ')\n",
    "words.__delitem__(0) # first element is just empty\n",
    "\n",
    "\n",
    "imgs = []\n",
    "for name,files in name_file.items():\n",
    "    if  name.__eq__('Maziar') or name.__eq__('Mehrdad') or name.__eq__('Sina'):\n",
    "        continue\n",
    "    for i,file in enumerate(files):\n",
    "        if i == 12:\n",
    "            break\n",
    "        imgs.append(file)\n",
    "    \n",
    "\n",
    "targets = [[w for w in word] for word in words]\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "lbl_enc.fit(alphabit)\n",
    "targets_enc = [lbl_enc.transform(word)+2 for word in targets]\n",
    "targets_enc = pad_words(targets_enc)\n",
    "dataset = {'imgs':imgs, \"labels\":targets_enc}\n",
    "df = pd.DataFrame(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e34b7d5",
   "metadata": {
    "papermill": {
     "duration": 0.008273,
     "end_time": "2023-12-02T18:36:09.036795",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.028522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13066bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.056011Z",
     "iopub.status.busy": "2023-12-02T18:36:09.055308Z",
     "iopub.status.idle": "2023-12-02T18:36:09.062503Z",
     "shell.execute_reply": "2023-12-02T18:36:09.061729Z"
    },
    "papermill": {
     "duration": 0.01952,
     "end_time": "2023-12-02T18:36:09.064795",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.045275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    \n",
    "    def __init__(self,df,trans=None):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        x = Image.open(self.df['imgs'][idx]).convert('RGB')\n",
    "        if trans:\n",
    "            x = trans(x)\n",
    "        y = self.df['labels'][idx] # +1 i have already add one in the above cell \n",
    "        return (x,y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96029ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.084484Z",
     "iopub.status.busy": "2023-12-02T18:36:09.083817Z",
     "iopub.status.idle": "2023-12-02T18:36:09.088130Z",
     "shell.execute_reply": "2023-12-02T18:36:09.087366Z"
    },
    "papermill": {
     "duration": 0.016778,
     "end_time": "2023-12-02T18:36:09.090236",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.073458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# std = torch.tensor([0.0603, 0.0606, 0.0347])\n",
    "# mean = torch.tensor([[0.8753, 0.8924, 0.9244]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6fb7f7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.109170Z",
     "iopub.status.busy": "2023-12-02T18:36:09.108762Z",
     "iopub.status.idle": "2023-12-02T18:36:09.115756Z",
     "shell.execute_reply": "2023-12-02T18:36:09.114895Z"
    },
    "papermill": {
     "duration": 0.019487,
     "end_time": "2023-12-02T18:36:09.118039",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.098552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(size=(20,80)),\n",
    "    transforms.Normalize(mean=(0.8753,0.8924,0.9244),std=(0.0603,0.0606,0.0347))\n",
    "                           ])\n",
    "all_imgs = []\n",
    "dataset = Mydataset(df,trans)\n",
    "\n",
    "    \n",
    "\n",
    "train_loader = DataLoader(dataset,batch_size=bs)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b2d770",
   "metadata": {
    "papermill": {
     "duration": 0.008031,
     "end_time": "2023-12-02T18:36:09.134645",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.126614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414cb6ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.153695Z",
     "iopub.status.busy": "2023-12-02T18:36:09.153055Z",
     "iopub.status.idle": "2023-12-02T18:36:09.205993Z",
     "shell.execute_reply": "2023-12-02T18:36:09.204693Z"
    },
    "papermill": {
     "duration": 0.065642,
     "end_time": "2023-12-02T18:36:09.208771",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.143129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ح'], dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test =  torch.tensor([ [ [1,2,3],[5,6,4] ],[[1,1,1],[2,2,2]] ])\n",
    "aaa = torch.argmax(test,dim=1)  \n",
    "# lbl_enc.inverse_transform\n",
    "a = [ t.shape for t in aaa]\n",
    "aaa.shape\n",
    "\n",
    "lbl_enc.inverse_transform(np.array([6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639e683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T17:52:49.630249Z",
     "iopub.status.busy": "2023-12-02T17:52:49.629885Z",
     "iopub.status.idle": "2023-12-02T17:52:49.636812Z",
     "shell.execute_reply": "2023-12-02T17:52:49.635494Z",
     "shell.execute_reply.started": "2023-12-02T17:52:49.630221Z"
    },
    "papermill": {
     "duration": 0.009047,
     "end_time": "2023-12-02T18:36:09.226918",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.217871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060baaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.246637Z",
     "iopub.status.busy": "2023-12-02T18:36:09.246209Z",
     "iopub.status.idle": "2023-12-02T18:36:09.254553Z",
     "shell.execute_reply": "2023-12-02T18:36:09.253350Z"
    },
    "papermill": {
     "duration": 0.020837,
     "end_time": "2023-12-02T18:36:09.256909",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.236072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def decode_pred(y_pred,targets):\n",
    "    \"\"\"\n",
    "    applying inverse_transform to convert numbers to characters\n",
    "    \"\"\"    \n",
    "    # first we need to remove blanks(0) and padding (1)\n",
    "    targets_filtered = [target[(target!=0) & (target!=1)]-2 for target in targets] \n",
    "    y_pred = torch.argmax(y_pred,dim=2).permute(1,0) \n",
    "    y_pred_filtered = [y[(y!=0) & (y!=1)]-2 for y in y_pred]\n",
    "\n",
    "    targets_dec = [lbl_enc.inverse_transform(tf) for tf in targets_filtered ]\n",
    "    y_pred_dec = [lbl_enc.inverse_transform(yf) for yf in y_pred_filtered ]\n",
    "    results = {\n",
    "        'targets_filtered':targets_filtered,\n",
    "        'y_pred_filtered':y_pred_filtered,\n",
    "        'targets_dec':targets_dec,\n",
    "        'y_pred_dec':y_pred_dec\n",
    "              }\n",
    "    return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265519c8",
   "metadata": {
    "papermill": {
     "duration": 0.008626,
     "end_time": "2023-12-02T18:36:09.274163",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.265537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d26f5be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.293423Z",
     "iopub.status.busy": "2023-12-02T18:36:09.293035Z",
     "iopub.status.idle": "2023-12-02T18:36:09.311992Z",
     "shell.execute_reply": "2023-12-02T18:36:09.310955Z"
    },
    "papermill": {
     "duration": 0.031789,
     "end_time": "2023-12-02T18:36:09.314517",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.282728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_map = torch.tensor([48, 84, 5, 20]) # bs,c,h,w\n",
    "\n",
    "class MyCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,12,3,2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(12,36,3,2,padding=1)\n",
    "        self.conv3 = nn.Conv2d(36,84,3,1,padding=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv2(F.relu(x))\n",
    "#         print(x.shape)\n",
    "        x = self.conv3(F.relu(x))\n",
    "        return x\n",
    "    \n",
    "class MyRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,num_layers,bi):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers        \n",
    "        self.bi = bi\n",
    "        self.D = 2 if self.bi else 1 \n",
    "        self.gru = nn.GRU(input_size,hidden_size,num_layers,bidirectional=bi,batch_first=True)\n",
    "        self.linear1 = nn.Linear(self.D*hidden_size,self.D*hidden_size)\n",
    "        self.linear2 = nn.Linear(self.D*hidden_size,num_output+2) # +2 for the blank ctc and padding\n",
    "        \n",
    "        \n",
    "    def forward(self,x): \n",
    "        # x : (bs,T,features)\n",
    "        h0 = torch.zeros(self.D*self.num_layers,x.size(0),self.hidden_size)\n",
    "        out,hn = self.gru(x,h0)\n",
    "        out = self.linear1(F.relu(out))\n",
    "        out = self.linear2(out)\n",
    "        out = F.log_softmax(out,dim=2)\n",
    "        out = out.permute(1,0,2)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "# class denseLayer(nn.Module):\n",
    "#     def __init__\n",
    "    \n",
    "    \n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,hidden_size,num_layers,bi):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers  \n",
    "        self.bi = bi\n",
    "        self.cnn = MyCNN()\n",
    "        self.rnn = MyRNN(feature_map[1]*feature_map[2],hidden_size,num_layers,bi)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.cnn(x)\n",
    "#         print(x.shape) # --> (bs,c,h,w)\n",
    "        x = x.view(-1,x.shape[3],x.shape[2]*x.shape[1]) # --> (bs,w,h*c)\n",
    "        \n",
    "        # i will assume that num of channels is the time_stamps \n",
    "        # i've changed my mind :) , w = time_stamps\n",
    "        # for rnn , we need (time_stamps,bs,featuers)\n",
    "        \n",
    "#         x = x.permute(1,0,2)  ### ????? BATCH_FIRST = TRUE\n",
    "#         print(x.shape)\n",
    "        x = self.rnn(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba434b8",
   "metadata": {
    "papermill": {
     "duration": 0.008246,
     "end_time": "2023-12-02T18:36:09.331464",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.323218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12107b1",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T18:36:09.350986Z",
     "iopub.status.busy": "2023-12-02T18:36:09.350563Z",
     "iopub.status.idle": "2023-12-02T18:38:56.744390Z",
     "shell.execute_reply": "2023-12-02T18:38:56.741999Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 167.405926,
     "end_time": "2023-12-02T18:38:56.746676",
     "exception": false,
     "start_time": "2023-12-02T18:36:09.340750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n"
     ]
    }
   ],
   "source": [
    "loss_fn =  nn.CTCLoss(blank=0)\n",
    "model = MyModel(300,2,True)\n",
    "lr = 1e-3\n",
    "optim = opt.Adam(model.parameters(),lr=lr) \n",
    "\n",
    "batch = next(iter(train_loader))       \n",
    "train_loss = []\n",
    "for epoch in range (500):\n",
    "    losses = 0\n",
    "    for batch in train_loader:\n",
    "        x,y = batch[0],batch[1]\n",
    "        out = model(batch[0])\n",
    "        input_lengths = torch.full(size=(x.shape[0],), fill_value=out.shape[0], dtype=torch.long)\n",
    "        target_lengths = torch.full(size=(x.shape[0],), fill_value=batch[1].size(1), dtype=torch.long)\n",
    "        optim.zero_grad()\n",
    "        loss = loss_fn(out,batch[1],input_lengths,target_lengths)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses += loss.item()\n",
    "    print(epoch)    \n",
    "    train_loss.append(losses/len(train_loader))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56dd0e",
   "metadata": {
    "papermill": {
     "duration": 0.053652,
     "end_time": "2023-12-02T18:38:56.855170",
     "exception": false,
     "start_time": "2023-12-02T18:38:56.801518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f93901",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:38:57.031982Z",
     "iopub.status.busy": "2023-12-02T18:38:57.031111Z",
     "iopub.status.idle": "2023-12-02T18:38:57.082275Z",
     "shell.execute_reply": "2023-12-02T18:38:57.081175Z"
    },
    "papermill": {
     "duration": 0.109658,
     "end_time": "2023-12-02T18:38:57.085027",
     "exception": false,
     "start_time": "2023-12-02T18:38:56.975369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets_filtered': [tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22])],\n",
       " 'y_pred_filtered': [tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 25, 24, 28, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22]),\n",
       "  tensor([ 7, 28,  1,  2,  1, 25]),\n",
       "  tensor([24, 28,  8,  1, 25]),\n",
       "  tensor([25, 24, 28, 28, 25]),\n",
       "  tensor([ 8, 28, 23, 24]),\n",
       "  tensor([24, 26, 10,  1, 25]),\n",
       "  tensor([22,  1, 13,  1, 25]),\n",
       "  tensor([ 2, 10,  6, 27,  1, 10]),\n",
       "  tensor([25,  1,  0, 28, 25]),\n",
       "  tensor([ 1, 23,  2, 10, 11]),\n",
       "  tensor([28, 28, 11,  8]),\n",
       "  tensor([ 3,  2, 10, 28, 11]),\n",
       "  tensor([12, 28, 10, 28, 22])],\n",
       " 'targets_dec': [array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1')],\n",
       " 'y_pred_dec': [array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'ن', 'م', 'ي', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n",
       "  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ن', 'م', 'ي', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n",
       "  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n",
       "  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n",
       "  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n",
       "  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n",
       "  array(['ي', 'ي', 'ز', 'د'], dtype='<U1'),\n",
       "  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n",
       "  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_pred(out,batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ef363d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-02T18:38:57.196755Z",
     "iopub.status.busy": "2023-12-02T18:38:57.195884Z",
     "iopub.status.idle": "2023-12-02T18:38:57.479099Z",
     "shell.execute_reply": "2023-12-02T18:38:57.477963Z"
    },
    "papermill": {
     "duration": 0.342238,
     "end_time": "2023-12-02T18:38:57.481596",
     "exception": false,
     "start_time": "2023-12-02T18:38:57.139358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f989a4d5f00>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsJ0lEQVR4nO3deXxU9b3/8ffMJDMEyMIWQiAsyib7HiN1q1TFDWtvq5QqVX9aNVatXlvwFpXaGtt6vbgVtyvaiuJSEW8rVArKooQdWZSAbAlL2LNB1pnv748kQyKJMjBzTnLm9Xw85sHknDOTz3zJg7z5bsdljDECAAAIA7fdBQAAAOcgWAAAgLAhWAAAgLAhWAAAgLAhWAAAgLAhWAAAgLAhWAAAgLAhWAAAgLCJsfobBgIB7d27V/Hx8XK5XFZ/ewAAcBqMMSouLlZqaqrc7sb7JSwPFnv37lVaWprV3xYAAIRBXl6eunTp0uh5y4NFfHy8pOrCEhISrP72AADgNBQVFSktLS34e7wxlgeL2uGPhIQEggUAAM3Md01jYPImAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG4IFAAAIG8cEi6fmb9FvP9igg8XldpcCAEDUckywmLUiV29k5xIsAACwkWOCRStf9R3gj1dU2VwJAADRyzHBoqXXI0k6VuG3uRIAAKKXY4JFK29Nj0U5PRYAANjFMcEijh4LAABs55hg0cpXHSyYYwEAgH0cEyxa1gyFHCunxwIAALs4Jli08tJjAQCA3RwTLFr66LEAAMBujgkW9FgAAGA/xwSL4BwLVoUAAGAbxwSL4KoQ9rEAAMA2jgkWJ3osCBYAANjFMcHixD4WDIUAAGAXxwSLE/tY0GMBAIBdHBMsgvcKoccCAADbOCZYtKwZCqHHAgAA+zgmWNTtsTDG2FwNAADRyTHBorbHoipgVOEP2FwNAADRyTnBItYTfH6cbb0BALCFY4JFjMctj9slSfRYAABgE8cEC0mK9dQEiyqCBQAAdnBYsKj+OFUBJm8CAGAHRwaLSoZCAACwhcOCBUMhAADYyWHBgqEQAADs5MhgwVAIAAD2CClY+P1+TZkyRT169FBcXJzOPvtsPfbYY01mp8vaoZBKhkIAALBFTCgX//GPf9T06dP1+uuvq3///lq1apVuvvlmJSYm6p577olUjaestseCfSwAALBHSMHi888/17hx43TllVdKkrp376633npLK1asiEhxoQrOsfA3jR4UAACiTUhDIeedd54WLFigLVu2SJK++OILLV26VGPHjm30NeXl5SoqKqr3iJTgUAg9FgAA2CKkHotJkyapqKhIffv2lcfjkd/v1x/+8AdNmDCh0ddkZWVp6tSpZ1zoqWAoBAAAe4XUY/HOO+9o5syZevPNN7VmzRq9/vrrevLJJ/X66683+prJkyersLAw+MjLyzvjohvDUAgAAPYKqcfiwQcf1KRJk3TDDTdIkgYOHKhdu3YpKytLEydObPA1Pp9PPp/vzCs9BQyFAABgr5B6LI4fPy63u/5LPB6PAoGm8YucfSwAALBXSD0WV199tf7whz+oa9eu6t+/v9auXaunnnpKt9xyS6TqC8mJYMFQCAAAdggpWDz77LOaMmWK7rrrLh04cECpqan6xS9+oYcffjhS9YUkhqEQAABsFVKwiI+P17Rp0zRt2rQIlXNmvAyFAABgK4feK4ShEAAA7OCoYMFQCAAA9nJUsGAoBAAAezkqWDAUAgCAvRwaLOixAADADo4KFsyxAADAXo4KFl6GQgAAsJWjggX3CgEAwF6OChYxzLEAAMBWjgoWDIUAAGAvRwWL2BiGQgAAsJOjgkWMm6EQAADs5KhgwQZZAADYy1HBwlszFFJFjwUAALZwVLCo7bGooMcCAABbOCpYMMcCAAB7OSpYMBQCAIC9HBUsmLwJAIC9HBUsaodCKuixAADAFo4KFl42yAIAwFaOCha1QyFVDIUAAGALRwWLGA9DIQAA2MlRwYLbpgMAYC9HBQuPqzpYGCMZw3AIAABWc1SwcNcEC0kKkCsAALCcs4KFu26wIFkAAGA1ZwWLE7lCfrosAACwnMOCxYlkQYcFAADWc1Sw8NTpsvCTLAAAsJyjgkWdDgvmWAAAYANHBQtP3aEQtrIAAMByjgoWdedYMBQCAID1nBUsWG4KAICtHBUspBNLTgMsNwUAwHKOCxa1K0PIFQAAWM9xwcJVM8+CORYAAFjPccGidmUIQyEAAFjPccEiOMeCHgsAACznvGDBHAsAAGzjvGBRO8eCZAEAgOUcFyxqV4UYhkIAALCc44JF7RwLVoUAAGA9BwaL2lUhNhcCAEAUcm6woMcCAADLOS5YnNh5k2ABAIDVHBcsam9wyqoQAACs57hgcWIoxOZCAACIQo4LFiw3BQDAPo4LFgyFAABgH8cFCw9DIQAA2MZxwYLlpgAA2Md5wYLlpgAA2MZ5wYI5FgAA2MZxweLEqhCbCwEAIAo5Lli4uG06AAC2cVyw8NQMhTDHAgAA6zkuWLAqBAAA+zgvWLjZxwIAALs4L1iwKgQAANs4Llhw23QAAOzjuGDBHAsAAOzj3GARsLkQAACikAODRfWffnosAACwnAODRe3OmwQLAACs5rxgwXJTAABsE3Kw2LNnj372s5+pXbt2iouL08CBA7Vq1apI1HZaWG4KAIB9YkK5+OjRoxo9erQuvvhizZ07Vx06dNDWrVvVpk2bSNUXshM3ISNYAABgtZCCxR//+EelpaVpxowZwWM9evQIe1FngpuQAQBgn5CGQj788EONGDFCP/7xj5WcnKyhQ4fq5Zdf/tbXlJeXq6ioqN4jkjwu5lgAAGCXkILF9u3bNX36dPXq1Uv/+te/dOedd+qee+7R66+/3uhrsrKylJiYGHykpaWdcdHfxs3dTQEAsE1IwSIQCGjYsGF6/PHHNXToUN1+++267bbb9MILLzT6msmTJ6uwsDD4yMvLO+Oiv42bLb0BALBNSMGiU6dO6tevX71j55xzjnJzcxt9jc/nU0JCQr1HJLmDcywi+m0AAEADQgoWo0ePVk5OTr1jW7ZsUbdu3cJa1JnwcK8QAABsE1Kw+NWvfqXs7Gw9/vjj+vrrr/Xmm2/qpZdeUmZmZqTqC5m75hMFmL0JAIDlQgoWI0eO1OzZs/XWW29pwIABeuyxxzRt2jRNmDAhUvWFzM2qEAAAbBPSPhaSdNVVV+mqq66KRC1hEZxjwVAIAACWc9y9Qth5EwAA+zguWLi4VwgAALZxXLBg500AAOzjuGDBBlkAANjHccGidiiE5aYAAFjPccGCoRAAAOzjuGDhZudNAABs47xgwRwLAABs47xgwXJTAABs47hgwRwLAADs47hgERwKIVkAAGA55wULJm8CAGAbBwaL6j+5CRkAANZzXLA4cRMymwsBACAKOS5YuGpvm84cCwAALOe4YOGp3dKbLgsAACznuGDBBlkAANjHecGidlVIwOZCAACIQo4NFqwKAQDAeo4LFp6aT2QIFgAAWM5xwYJVIQAA2MdxwcLNvUIAALCN44JF7VAIq0IAALCe44IF9woBAMA+zg0WLDcFAMByjg0WLDcFAMB6jgsWLDcFAMA+jgsWLDcFAMA+jgsWHpabAgBgG8cFCzfLTQEAsI3zggXLTQEAsI1jg4Wf5aYAAFjOccHC464OFqwKAQDAeo4LFjUdFqwKAQDABo4LFh7mWAAAYBvHBQu3m+WmAADYxXnBgh4LAABs48BgUf0ncywAALCeA4NF7aoQmwsBACAKOS5Y1C43pccCAADrOTZYVBEsAACwnOOChTem+iNVsvUmAACWc16w8BAsAACwi+OCRWxNsKioIlgAAGA1xwWL2qGQqoBRgHkWAABYynHBItbjCj6vDNBrAQCAlRwYLE58JIZDAACwluOChbdOsKj0MxQCAICVHBcs3G6XYmr2smBlCAAA1nJcsJBYGQIAgF0cGiyqeywq6LEAAMBSjgwW3hiPJIZCAACwmjODRU2PRWUVkzcBALCSI4NFbM0mWRV+v82VAAAQXRwZLLzByZv0WAAAYCVHBotYbkQGAIAtnBksYlhuCgCAHRwZLIKTN+mxAADAUs4MFsHJmwQLAACs5Mhgwc6bAADYw9HBgpuQAQBgLUcGi9qhEOZYAABgLWcGC4ZCAACwhSODBTchAwDAHo4MFgyFAABgD0cGC3beBADAHmcULJ544gm5XC7dd999YSonPJhjAQCAPU47WKxcuVIvvviiBg0aFM56wqK2x+LlJTv02deHbK4GAIDocVrBoqSkRBMmTNDLL7+sNm3ahLumM1Y7x0KSJryy3MZKAACILqcVLDIzM3XllVdqzJgx33lteXm5ioqK6j0irbbHAgAAWCsm1BfMmjVLa9as0cqVK0/p+qysLE2dOjXkws5E7XJTAABgrZD+a5+Xl6d7771XM2fOVIsWLU7pNZMnT1ZhYWHwkZeXd1qFhsIXQ48FAAB2CKnHYvXq1Tpw4ICGDRsWPOb3+7V48WI999xzKi8vl8fjqfcan88nn88XnmpPEUMhAADYI6Rgcckll2jDhg31jt18883q27evfvOb35wUKuxSN1h43AyLAABglZCCRXx8vAYMGFDvWKtWrdSuXbuTjtupvM7+FW1beW2sBACA6OLIMYPDJeXB5x4XPRYAAFgl5FUh3/Tpp5+GoYzwSqrTS8GNyAAAsI4jeyx+MqKLLujdQZJUybbeAABYxpHBwhfjUdZ1AyVJ5fRYAABgGUcGC+nEJlmV/oCMMTZXAwBAdHBssPDVLH01RqoKECwAALCCY4NF3RuRcft0AACs4dhgUfd+IZXMswAAwBKODRYxHrdqN92kxwIAAGs4NlhIJ4ZDygkWAABYwtHBovaeIQyFAABgDUcHi9rbp7P7JgAA1nB0sPDW9FgwxwIAAGs4OljExjAUAgCAlRwdLGp7LJi8CQCANRwdLE5M3mTnTQAArODoYFG73JQ5FgAAWINgAQAAwsbZwaJ2VYjfryPHKmyuBgAA53N2sKjpsXhi7mYNe2y+lmw9aHNFAAA4m7ODRU2Pxf6icknSr97+ws5yAABwPEcHi9iY+h/vUEm5TZUAABAdHB0sanss6goEWHoKAECkODtYxJz88XYdOW5DJQAARAdnBwuP66RjOflFNlQCAEB0cHawaKDH4mAx8ywAAIiU6AsWJexnAQBApDg6WMQ2MHmTHgsAACLH0cFiYOfE4PP+qQmSWHIKAEAkxdhdQCRdck5HfT7p+9pfVKZ9hWW6a+YaggUAABHk6GAhSalJcUpNilNg1xFJDIUAABBJjh4Kqat9a5+k6qEQY4x2Hz2uo9yYDACAsIq6YFFWGdDavAJd8t+LNP7lbJurAgDAWaImWLTyxail1yNJ+uWba1VeFdDm/GIdKC6zuTIAAJwjaoKFJKUktJAk7SkoDR7btJedOAEACJeoChYD6iw/rfUlwQIAgLCJqmAxtGvSScc27S20vhAAABwqqoLFsK5tgs+vG9pZkrRxDz0WAACES1QFi3M6JQSfTzi3qyQp98hxFZVV2lUSAACO4vgNsuryxrj19u3nqqC0UsO7tVXnpDjtKSjVl3uLdO5Z7ewuDwCAZi+qgoUkpdcJEP1TE7SnoFT/2pSveRvzld6jrcYO7GRjdQAANG9RNRTyTf1Tq1eJzPhsp177fKfunLlGf1+92+aqAABovqI6WFzYp8NJx95fS7AAAOB0RXWwGJKWpFduGqH0Hm015ap+kqTl24+osJTJnAAAnI6oDhaSNKZfR739iwzd+r0e6pXcWlUBo0VbDtpdFgAAzVLUB4u6LqoZGvls6yGbKwEAoHkiWNQxumd7SdLSrw/JGGNzNQAAND8EizpG9WirWI9LewpKte1gid3lAADQ7BAs6mjpjdH3anotxjy1WA/P2agv8grsLQoAgGaEYPENv768r9yu6ud/XbZLP35xWb3brAMAgMYRLL7hnE4JevLHg/Wzc7uqQ7xPFVUB/ffHOXaXBQBAs0CwaMB1w7ro99cO1Cs3jZAkzV67h9urAwBwCggW32JwWpKuHpwqY6Rxz32m7/1xod7I3mV3WQAANFkEi+8waWxfdU6KU1XAaPfRUv32g42azbbfAAA0iGDxHTonxWnBAxfqpRuHa8w5HSVJT/5riyqqAjZXBgBA00OwOAUtYj26tH+KnvvpUHWI92lPQaleWrzN7rIAAGhyCBYhaBHr0aTL+0qSnvx4iy740yd6ZM5GlVX6ba4MAICmgWARouuGddbEjG6SpNwjx/X6sl26/W+rVelnaAQAAIJFiFwul6aOG6C1U36g5386TC29Hi3eclCT/r6BngsAQNQjWJymNq28unJQJ027fohcLunva3br4ic/1byN+XaXBgCAbQgWZ+jS/il6deJIdUpsoX2FZbpz5mq9unSH3WUBAGALgkUYXNw3WZ/850W6KaObjJF+948v9bv/+1LHK6rsLg0AAEsRLMKkRaxHU6/pr9/UrBp59bMdGvn7f+vN5bkyxthcHQAA1iBYhJHL5dKdF52tZ8YPVeekOB2r8Ouh2Rv0vwyNAACiBMEiAq4ZnKolv75Y91zSS5L0h4++0kcb9tlcFQAAkUewiBC326VfjemlG8+tnndx39vrtGrnEbvLAgAgoggWEeRyufTI1f005pxkVVQF9PMZKzVvYz5zLgAAjhVSsMjKytLIkSMVHx+v5ORkXXvttcrJyYlUbY4Q43HrmfFDld6jrUrKq3THG6s14ZXlyskvtrs0AADCLqRgsWjRImVmZio7O1vz589XZWWlLr30Uh07dixS9TlCS2+M/nrrKN1x4dnyetz6fNthXfXsEj2zYKvKq9itEwDgHC5zBv3yBw8eVHJyshYtWqQLLrjglF5TVFSkxMREFRYWKiEh4XS/dbOVd+S4pv7fl/r3V/slSZ0SW+iX3++l60emyeN22VwdAAANO9Xf32c0x6KwsFCS1LZt20avKS8vV1FRUb1HNEtr21Iv3zRcT98wRCkJ1bt1PjR7g66b/rk+3pQvf4D5FwCA5uu0eywCgYCuueYaFRQUaOnSpY1e9+ijj2rq1KknHY/WHou6yir9mrk8V/8zf4tKyqt36TynU4KeHT9EPZPjba4OAIATTrXH4rSDxZ133qm5c+dq6dKl6tKlS6PXlZeXq7y8vF5haWlpBIs69heV6bXPd2pm9i4VlVUp3hej6T8bru/1am93aQAASIpwsLj77rs1Z84cLV68WD169IhIYdHoQHGZ7p65Vit2HpHLJd12/ll64NLe8sV47C4NABDlIjLHwhiju+++W7Nnz9bChQtDDhX4dsnxLfTXW0dp/Kg0GSO9tHi7xj69RNnbD9tdGgAApySkYJGZmak33nhDb775puLj45Wfn6/8/HyVlpZGqr6o0yLWo6zrBumlG4erfWufth88phteytZDszeouKzS7vIAAPhWIQ2FuFwNL4ecMWOGfv7zn5/SezAUcuoKSyv1p3mbNXN5riSpc1KcnvrJYKWf1c7mygAA0SbikzdPF8EidMu2HdZv/r5euUeOy+WSbr/gLN3z/V5q5YuxuzQAQJSwZB8LWCPj7Haae+/5+smILjJGenHRdl02bbHW5RXYXRoAAPUQLJqJVr4Y/ek/BuulG4erc1Kcdh8t1U9fztaKHdwxFQDQdBAsmplL+6do7n3na3TPdjpe4deEV7L11orcRq+vqApYWB0AINoRLJqhhBaxeuWmkbq8f4oq/UaT39+gX7/3hXYcOnEzuILjFbr+xWXq/du5euwfX9pYLQAgmjB5sxkzxugvn27Tkx/nqPZv8eI+HXRp/xTtPHxMLy7aLklKjIvVmik/4CZnAIDTdqq/v1lW0Iy5XC5lXtxTAzsn6rlPvtbKnUf0Sc5BfZJzsN51haWV+mpfkQZ0TrSpUgBAtKDHwkE25xfp1tdWaU9B9YZlg9OS1L6VVws2H1Dvjq1VWFqp5386TCO6N343WgAAGsJy0yjUNyVBL944PPj1Az/oHbyR2Zb9JdpfVK4/zcthB08AQMQQLBxmQOdEPXRFXz14WR+d36u9rh+Zpp7JrYPnV+w8ooGPfqw3snfZWCUAwKkYCokCewtK9erSHXpl6Y56xz/IHK0haUn2FAUAaFYYCkFQalKcfntVPz14WR8lxsUqMS5WkvTKku02VwYAcBp6LKKMMUZf7SvWFc8skSR5PW5dNaiTnrp+yEnXvrR4mw4Wl+uhK85p9AZ0AIDoQI8FGuRyudQvNUF3XHi2JKnCH9D7a/dozro99a5bv7tAj3+0WS8v2aH1uwvtKBUA0AwRLKLUpLF99fGvLtDAmr0t7p21Tjf+73LtPnpckjTt31uD1y7fcdiWGgEAzQ/BIor17hivv94yShf27iC3S1qy9ZB+/MIyPTF3sxZuPhC8bvl2bnQGADg1BIso16aVV6/fMkoLH7hIZ3VopX2FZXph0TZJUv/U6jG0BZsP6E/zNsvi6TgAgGaIYAFJUvf2rfTOLzJ0y+ge6pXcWn1T4vWXCcPUr1N1uPjLp9v053/lqLTCb3OlAICmjFUh+Fb+gNH/zN+i5z75WlL1Dc2uGtRJmRf3VGpSnM3VAQCswqoQhIXH7dL9P+it3187QG1beVVYWqmZy3P18JxNdpcGAGiCCBb4Tm63Sz87t5veuyNDg7pUryL591f7dfm0xZqzbg9zLwAAQQQLnLKzOrTWh3d/T1cO7CRJ2pxfrHtnreO+IwCAIIIFQpb1o4F6ZvxQ3TAyTZI0Zc4m/XzGCh2vqKp3nTGGO6kCQJQhWCBkCS1idc3gVD3+w4G6blhnSdKnOQf1i7+tVn5hWfC6SX/foMFTP9aybWywBQDRgmCB0+Z2u/TUT4bozdvS5fW4tWTrIV3+9GIt3LxfH6zdo7dX5SlgpL8u22l3qQAAi7DcFGGxcU+hHpq9ocH7ing9bq38rzE6UFwmb4xb3dq1sqFCAMCZYLkpLDWgc6Leu+M8/fy87sFjw7u1Ue+OrVXhD+gXb6zSZdMW69rnP1N5FZtsAYBTxdhdAJzDG+PWo9f0109GpGn5jsMaN6SzXlmyXVv2lyi75n4jR49Xal1ugdLPamdztQCASKDHAmHXLzVBN4/uobatvLqgd4eTzj/43nq9uypPhccr2SIcAByGYIGIGta1TfD58G7Vz3OPHNeD763X4N99rHMenqc56/bYVR4AIMwIFogob4xbL904XA/8oLeevmGIvDEn/8j95u/rbagMABAJrAqBpXYfPa74FrG67a+rtGLHkeDxBy/ro4yz29Xr4QAANB2n+vubYAFb7Dp8TL//51datfOIjh4/sTvn4C6JGtQlSb8b118ul8vGCgEAdbHcFE1at3at9PJNI7TwgYs0MaNb8PgXuwv1t+xd2nawxMbqAACni2ABW7Vp5dXUcQM0fcKwesdfWbJD8zbm6+ixCpsqAwCcDoIFmoSL+iTX+3rWyjzd8cZq/ee7X9hUEQDgdBAs0CTEeT16944M3fP9nvWOL956UKt2HlGVP2BTZQCAULDzJpqMkd3bamT3tmrbyqs2rbz607wc7Sko1X+8sEy/vryP7rqo53e/CQDAVvRYoMn5+egeGjeks0Z2P7H09G/LdgWfl1f5Nf6lbGXOXCOLFzUBAL4DwQJN1sQ6NzTbV1imOev2yBijRTkHtWz7Yf1zwz590cDdVAEA9iFYoMka2rWNdmRdoR7tq2+zfu+sdZoyZ6Nu/9vq4DXvrc6zqzwAQAMIFmjSXC6Xxg5ICX79RnZuvfNzN+QzHAIATQjBAk3eA5f20ZzM0fK4T+zEOX5UV3lj3Dp8rELbDh6zsToAQF2sCkGT53G7NDgtSc/cMFRLvz6oSWPPUWJcrLYfLNHyHUe0aucR9UxubXeZAADRY4Fm5MpBnZR13SAlxsVKql6eKkmT3t+g9bsLbKwMAFCLYIFm64LeHYLPH/lwk42VAABqESzQbI3q0VZP3zBEkrQ2t0B9p8zVyp1Hvv1FAICIIligWRs3pLP6p1bfvresMqAXF20Pnsvefljr8gpsqgwAohPBAs1e3Y201uQeVSBg9NsPNuiGl7L105ezVVbpt684AIgyrApBs/fj4V00olsbXfXsUh05VqGzHvooeO54hV85+cUanJZkX4EAEEXosUCz53K5dFaH1rqoT4cGz2/aW2RxRQAQveixgGM8Nm6ALuuforhYj1wul1btOqIXF23Xpr2F2pxfpK5tW6qllx95AIgk/pWFY7Rr7dO4IZ2DX5fWzK2YuTxXM5fn6oqBKfrLhOF2lQcAUYGhEDjW0G/Mq/hoQ74OFJXZUwwARAmCBRwrrW1LPXJ1v3rH/r5mj03VAEB0IFjA0W4e3UNLfn2xfjeuvyTp5SXbtWF3IXdEBYAIIVjA8dLattRPRqSpbSuvjhyr0NXPLdX0RdvsLgsAHIlggajQItajOy48K/j1Ux9v0cY9hTZWBADORLBA1Ljt/LO05NcX69J+HVUVMPrV2+t09FiF3WUBgKMQLBA1XC6X0tq21BM/GqT2rX3aeqBEVz27VHsKSu0uDQAcg2CBqNO2lVdv/L9R6t6upfYUlGrCy9laveuo3WUBgCMQLBCV+qYk6M3bzlWnxBbaefi4xr+UrbdW5KrKH7C7NABo1ggWiFqpSXH66J7zdVn/jqrwBzT5/Q268X9X6HhFld2lAUCzRbBAVGvTyqu/TBiuBy/ro5Zej5ZtP6xL/2ex3l+zW4EAe10AQKgIFoh6HrdLmRf31N9uTVdyvE+7j5bq/ne+0I2vLlf29sNspgUAIXAZi//VLCoqUmJiogoLC5WQkGDltwa+U2mFX69+tkPPLtyqssrq+RbDu7XRDSPTNHZgJ7X2cd8+ANHpVH9/n1aPxfPPP6/u3burRYsWSk9P14oVK067UKApifN6lHlxT310z/m6YWSavDFurd51VA++t14jf/9v3f/2On28KV9FZZV2lwoATVLIPRZvv/22brrpJr3wwgtKT0/XtGnT9O677yonJ0fJycnf+Xp6LNCc7C8q03urd+u91bu149Cx4HGP26XeHeM1uEuiBnZJVN+UBPVJiadHA4Bjnerv75CDRXp6ukaOHKnnnntOkhQIBJSWlqZf/vKXmjRpUtgKA5oSY4zW5BZozro9WrL1UL2QUVf71l61b+2reXjVrs7z9vE+JcXFqkWsR74Yt1rEemoebvliPPK4XRZ/KgA4daf6+zuk/15VVFRo9erVmjx5cvCY2+3WmDFjtGzZsgZfU15ervLy8nqFAc2Ny+XS8G5tNLxbG0lSfmGZ1uUVaP3uAm3cW6Qt+cXKLyrToZIKHSqpkFQc8veI9bjki/HI7aruEQk+XC65v/E8xu2S21V9zO12yeOS3C6XXC7JpZqA4pJcUvCYy6V65121l7lcda6r/rrm5TXXuOqcq//64NcNZKLGYlLt+5/atWf2vo1e38ibuBo40cjbNvgWjV8bwvuGUHBo7XNqdYVTY58xbO8f2bdv9GeqOXjg0t6KbxFry/cOKVgcOnRIfr9fHTt2rHe8Y8eO2rx5c4OvycrK0tSpU0+/QqAJSklsocsTU3T5gJTgsYLjFdpTUKrDJRU6VFKuQyXlOlxSoYMl5TpUUqHDJeUqLK1UWWVA5ZV+lVX5Vek/0WFY6Teq9LOHBoAzd9fFZzePYHE6Jk+erPvvvz/4dVFRkdLS0iL9bQHLJbX0KqmlN6TX+ANGZZV+lVX6VV4VUHlVQP6AUcAY+QPmpOf+gJHfGAUCqvnzxDFjjGoHNo0kYyQjU/On6i2brXeuzvngFSe99sTXte+vmusbGkxtbIS1oaONDcY2fG1oi9garK3Bd27s2si8b2Ma+nyhtU9j1576+4ZLxJcbRvgDRLr+SLd/S699871C+s7t27eXx+PR/v376x3fv3+/UlJSGnyNz+eTz+c7/QoBB/O4XWrli1ErJn0CcIiQlpt6vV4NHz5cCxYsCB4LBAJasGCBMjIywl4cAABoXkL+b9L999+viRMnasSIERo1apSmTZumY8eO6eabb45EfQAAoBkJOVhcf/31OnjwoB5++GHl5+dryJAhmjdv3kkTOgEAQPRhS28AAPCdIrqlNwAAQEMIFgAAIGwIFgAAIGwIFgAAIGwIFgAAIGwIFgAAIGwIFgAAIGwIFgAAIGwIFgAAIGwsv6Vi7UafRUVFVn9rAABwmmp/b3/Xht2WB4vi4mJJUlpamtXfGgAAnKHi4mIlJiY2et7ye4UEAgHt3btX8fHxcrlcYXvfoqIipaWlKS8vj3uQRBhtbQ3a2Rq0s3Voa2tEqp2NMSouLlZqaqrc7sZnUljeY+F2u9WlS5eIvX9CQgI/sBahra1BO1uDdrYObW2NSLTzt/VU1GLyJgAACBuCBQAACBvHBAufz6dHHnlEPp/P7lIcj7a2Bu1sDdrZOrS1NexuZ8snbwIAAOdyTI8FAACwH8ECAACEDcECAACEDcECAACEjWOCxfPPP6/u3burRYsWSk9P14oVK+wuqVlZvHixrr76aqWmpsrlcumDDz6od94Yo4cfflidOnVSXFycxowZo61bt9a75siRI5owYYISEhKUlJSkW2+9VSUlJRZ+iqYvKytLI0eOVHx8vJKTk3XttdcqJyen3jVlZWXKzMxUu3bt1Lp1a/3oRz/S/v37612Tm5urK6+8Ui1btlRycrIefPBBVVVVWflRmrTp06dr0KBBwQ2CMjIyNHfu3OB52jgynnjiCblcLt13333BY7R1eDz66KNyuVz1Hn379g2eb1LtbBxg1qxZxuv1mldffdVs2rTJ3HbbbSYpKcns37/f7tKajY8++sj813/9l3n//feNJDN79ux655944gmTmJhoPvjgA/PFF1+Ya665xvTo0cOUlpYGr7n88svN4MGDTXZ2tlmyZInp2bOnGT9+vMWfpGm77LLLzIwZM8zGjRvNunXrzBVXXGG6du1qSkpKgtfccccdJi0tzSxYsMCsWrXKnHvuuea8884Lnq+qqjIDBgwwY8aMMWvXrjUfffSRad++vZk8ebIdH6lJ+vDDD80///lPs2XLFpOTk2MeeughExsbazZu3GiMoY0jYcWKFaZ79+5m0KBB5t577w0ep63D45FHHjH9+/c3+/btCz4OHjwYPN+U2tkRwWLUqFEmMzMz+LXf7zepqakmKyvLxqqar28Gi0AgYFJSUsyf//zn4LGCggLj8/nMW2+9ZYwx5ssvvzSSzMqVK4PXzJ0717hcLrNnzx7Lam9uDhw4YCSZRYsWGWOq2zU2Nta8++67wWu++uorI8ksW7bMGFMdAt1ut8nPzw9eM336dJOQkGDKy8ut/QDNSJs2bcwrr7xCG0dAcXGx6dWrl5k/f7658MILg8GCtg6fRx55xAwePLjBc02tnZv9UEhFRYVWr16tMWPGBI+53W6NGTNGy5Yts7Ey59ixY4fy8/PrtXFiYqLS09ODbbxs2TIlJSVpxIgRwWvGjBkjt9ut5cuXW15zc1FYWChJatu2rSRp9erVqqysrNfWffv2VdeuXeu19cCBA9WxY8fgNZdddpmKioq0adMmC6tvHvx+v2bNmqVjx44pIyODNo6AzMxMXXnllfXaVOLnOdy2bt2q1NRUnXXWWZowYYJyc3MlNb12tvwmZOF26NAh+f3+eo0lSR07dtTmzZttqspZ8vPzJanBNq49l5+fr+Tk5HrnY2Ji1LZt2+A1qC8QCOi+++7T6NGjNWDAAEnV7ej1epWUlFTv2m+2dUN/F7XnUG3Dhg3KyMhQWVmZWrdurdmzZ6tfv35at24dbRxGs2bN0po1a7Ry5cqTzvHzHD7p6el67bXX1KdPH+3bt09Tp07V+eefr40bNza5dm72wQJorjIzM7Vx40YtXbrU7lIcqU+fPlq3bp0KCwv13nvvaeLEiVq0aJHdZTlKXl6e7r33Xs2fP18tWrSwuxxHGzt2bPD5oEGDlJ6erm7duumdd95RXFycjZWdrNkPhbRv314ej+ek2a/79+9XSkqKTVU5S207flsbp6Sk6MCBA/XOV1VV6ciRI/w9NODuu+/WP/7xD33yySfq0qVL8HhKSooqKipUUFBQ7/pvtnVDfxe151DN6/WqZ8+eGj58uLKysjR48GA9/fTTtHEYrV69WgcOHNCwYcMUExOjmJgYLVq0SM8884xiYmLUsWNH2jpCkpKS1Lt3b3399ddN7me62QcLr9er4cOHa8GCBcFjgUBACxYsUEZGho2VOUePHj2UkpJSr42Lioq0fPnyYBtnZGSooKBAq1evDl6zcOFCBQIBpaenW15zU2WM0d13363Zs2dr4cKF6tGjR73zw4cPV2xsbL22zsnJUW5ubr223rBhQ70gN3/+fCUkJKhfv37WfJBmKBAIqLy8nDYOo0suuUQbNmzQunXrgo8RI0ZowoQJwee0dWSUlJRo27Zt6tSpU9P7mQ7rVFCbzJo1y/h8PvPaa6+ZL7/80tx+++0mKSmp3uxXfLvi4mKzdu1as3btWiPJPPXUU2bt2rVm165dxpjq5aZJSUlmzpw5Zv369WbcuHENLjcdOnSoWb58uVm6dKnp1asXy02/4c477zSJiYnm008/rbds7Pjx48Fr7rjjDtO1a1ezcOFCs2rVKpORkWEyMjKC52uXjV166aVm3bp1Zt68eaZDhw4sz6tj0qRJZtGiRWbHjh1m/fr1ZtKkScblcpmPP/7YGEMbR1LdVSHG0Nbh8sADD5hPP/3U7Nixw3z22WdmzJgxpn379ubAgQPGmKbVzo4IFsYY8+yzz5quXbsar9drRo0aZbKzs+0uqVn55JNPjKSTHhMnTjTGVC85nTJliunYsaPx+XzmkksuMTk5OfXe4/Dhw2b8+PGmdevWJiEhwdx8882muLjYhk/TdDXUxpLMjBkzgteUlpaau+66y7Rp08a0bNnS/PCHPzT79u2r9z47d+40Y8eONXFxcaZ9+/bmgQceMJWVlRZ/mqbrlltuMd26dTNer9d06NDBXHLJJcFQYQxtHEnfDBa0dXhcf/31plOnTsbr9ZrOnTub66+/3nz99dfB802pnbltOgAACJtmP8cCAAA0HQQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNgQLAAAQNv8fBUsITLT2KvEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766a6424",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T18:38:57.593183Z",
     "iopub.status.busy": "2023-12-02T18:38:57.592771Z",
     "iopub.status.idle": "2023-12-02T18:38:57.606868Z",
     "shell.execute_reply": "2023-12-02T18:38:57.605806Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.07315,
     "end_time": "2023-12-02T18:38:57.609546",
     "exception": false,
     "start_time": "2023-12-02T18:38:57.536396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.797950744628906,\n",
       " 8.29289722442627,\n",
       " 7.225500583648682,\n",
       " 4.778061389923096,\n",
       " 3.818382978439331,\n",
       " 4.037731170654297,\n",
       " 3.1267426013946533,\n",
       " 3.121886968612671,\n",
       " 3.341510534286499,\n",
       " 3.2212696075439453,\n",
       " 2.9611356258392334,\n",
       " 2.853769540786743,\n",
       " 2.9601147174835205,\n",
       " 3.0039546489715576,\n",
       " 2.884211301803589,\n",
       " 2.7581100463867188,\n",
       " 2.741041898727417,\n",
       " 2.7779769897460938,\n",
       " 2.7690937519073486,\n",
       " 2.6926724910736084,\n",
       " 2.6030521392822266,\n",
       " 2.5624256134033203,\n",
       " 2.568591833114624,\n",
       " 2.564307928085327,\n",
       " 2.5235464572906494,\n",
       " 2.4778566360473633,\n",
       " 2.465055227279663,\n",
       " 2.470881938934326,\n",
       " 2.449620485305786,\n",
       " 2.40290904045105,\n",
       " 2.370309591293335,\n",
       " 2.3653581142425537,\n",
       " 2.361539125442505,\n",
       " 2.3388047218322754,\n",
       " 2.3097083568573,\n",
       " 2.2937586307525635,\n",
       " 2.2820799350738525,\n",
       " 2.2602622509002686,\n",
       " 2.235989570617676,\n",
       " 2.219076156616211,\n",
       " 2.211838960647583,\n",
       " 2.1951942443847656,\n",
       " 2.1668851375579834,\n",
       " 2.1377851963043213,\n",
       " 2.114175319671631,\n",
       " 2.094036817550659,\n",
       " 2.081165313720703,\n",
       " 2.0678422451019287,\n",
       " 2.051201581954956,\n",
       " 2.0367653369903564,\n",
       " 2.0261943340301514,\n",
       " 2.0125315189361572,\n",
       " 1.9968994855880737,\n",
       " 1.9853845834732056,\n",
       " 1.9759904146194458,\n",
       " 1.9585639238357544,\n",
       " 1.9373741149902344,\n",
       " 1.9205816984176636,\n",
       " 1.9041167497634888,\n",
       " 1.8908600807189941,\n",
       " 1.8746286630630493,\n",
       " 1.8600231409072876,\n",
       " 1.843251347541809,\n",
       " 1.8257001638412476,\n",
       " 1.8094347715377808,\n",
       " 1.7958602905273438,\n",
       " 1.7785512208938599,\n",
       " 1.7543565034866333,\n",
       " 1.7347115278244019,\n",
       " 1.7164325714111328,\n",
       " 1.6976858377456665,\n",
       " 1.6921849250793457,\n",
       " 1.67880380153656,\n",
       " 1.6757735013961792,\n",
       " 1.6186293363571167,\n",
       " 1.6658587455749512,\n",
       " 1.7107996940612793,\n",
       " 1.7160354852676392,\n",
       " 1.6246594190597534,\n",
       " 1.5949716567993164,\n",
       " 1.63483464717865,\n",
       " 1.5577826499938965,\n",
       " 1.5868911743164062,\n",
       " 1.566698670387268,\n",
       " 1.513372778892517,\n",
       " 1.4970746040344238,\n",
       " 1.5039457082748413,\n",
       " 1.458846092224121,\n",
       " 1.4532536268234253,\n",
       " 1.439265251159668,\n",
       " 1.4155246019363403,\n",
       " 1.4065872430801392,\n",
       " 1.4040330648422241,\n",
       " 1.4531941413879395,\n",
       " 1.4981542825698853,\n",
       " 1.400946021080017,\n",
       " 1.3947539329528809,\n",
       " 1.363146424293518,\n",
       " 1.3535984754562378,\n",
       " 1.3307124376296997,\n",
       " 1.337201476097107,\n",
       " 1.2868918180465698,\n",
       " 1.2891954183578491,\n",
       " 1.279375672340393,\n",
       " 1.2463310956954956,\n",
       " 1.2398831844329834,\n",
       " 1.2113057374954224,\n",
       " 1.1976532936096191,\n",
       " 1.1797512769699097,\n",
       " 1.1616501808166504,\n",
       " 1.153130054473877,\n",
       " 1.1852824687957764,\n",
       " 1.2199374437332153,\n",
       " 1.154678463935852,\n",
       " 1.0700387954711914,\n",
       " 1.1258012056350708,\n",
       " 1.1464940309524536,\n",
       " 1.0549319982528687,\n",
       " 1.0718027353286743,\n",
       " 1.0679155588150024,\n",
       " 1.0148191452026367,\n",
       " 1.0624477863311768,\n",
       " 0.9963710308074951,\n",
       " 0.9887788891792297,\n",
       " 0.9895679950714111,\n",
       " 0.9166465401649475,\n",
       " 0.9768886566162109,\n",
       " 0.8882474303245544,\n",
       " 0.9096795916557312,\n",
       " 0.9112059473991394,\n",
       " 0.8251102566719055,\n",
       " 0.8571114540100098,\n",
       " 0.7671629786491394,\n",
       " 0.7821211218833923,\n",
       " 0.7280710339546204,\n",
       " 0.7567915320396423,\n",
       " 0.7522251009941101,\n",
       " 0.822901725769043,\n",
       " 0.7598622441291809,\n",
       " 0.659757673740387,\n",
       " 0.6569765210151672,\n",
       " 0.5845484137535095,\n",
       " 0.6125724911689758,\n",
       " 0.5259644389152527,\n",
       " 0.5368654131889343,\n",
       " 0.5259589552879333,\n",
       " 0.5561156272888184,\n",
       " 0.5728893876075745,\n",
       " 0.449434369802475,\n",
       " 0.42573198676109314,\n",
       " 0.46459606289863586,\n",
       " 0.40196457505226135,\n",
       " 0.34882852435112,\n",
       " 0.35938942432403564,\n",
       " 0.32415562868118286,\n",
       " 0.2910815477371216,\n",
       " 0.27358728647232056,\n",
       " 0.24655646085739136,\n",
       " 0.23192648589611053,\n",
       " 0.20967821776866913,\n",
       " 0.19876615703105927,\n",
       " 0.17473852634429932,\n",
       " 0.16226881742477417,\n",
       " 0.14947347342967987,\n",
       " 0.13260912895202637,\n",
       " 0.12392812967300415,\n",
       " 0.11153281480073929,\n",
       " 0.10255453735589981,\n",
       " 0.0939968004822731,\n",
       " 0.0842982828617096,\n",
       " 0.07640837877988815,\n",
       " 0.0715702548623085,\n",
       " 0.063865527510643,\n",
       " 0.058062728494405746,\n",
       " 0.052883416414260864,\n",
       " 0.04903353750705719,\n",
       " 0.04444284737110138,\n",
       " 0.0399065762758255,\n",
       " 0.0366167351603508,\n",
       " 0.034214019775390625,\n",
       " 0.0312662310898304,\n",
       " 0.02787376008927822,\n",
       " 0.025862475857138634,\n",
       " 0.024450423195958138,\n",
       " 0.022405194118618965,\n",
       " 0.020465174689888954,\n",
       " 0.01900547184050083,\n",
       " 0.01779569685459137,\n",
       " 0.016697559505701065,\n",
       " 0.01560957357287407,\n",
       " 0.014576242305338383,\n",
       " 0.013709921389818192,\n",
       " 0.0129648856818676,\n",
       " 0.012205946259200573,\n",
       " 0.011488615535199642,\n",
       " 0.010904974304139614,\n",
       " 0.010411807335913181,\n",
       " 0.00993981584906578,\n",
       " 0.009482200257480145,\n",
       " 0.009059973992407322,\n",
       " 0.008665512315928936,\n",
       " 0.008298738859593868,\n",
       " 0.007979106158018112,\n",
       " 0.0076926336623728275,\n",
       " 0.007414929568767548,\n",
       " 0.007144099101424217,\n",
       " 0.006893526297062635,\n",
       " 0.006669068243354559,\n",
       " 0.006462527438998222,\n",
       " 0.006267150864005089,\n",
       " 0.006083352025598288,\n",
       " 0.005911560263484716,\n",
       " 0.005741605069488287,\n",
       " 0.005578473210334778,\n",
       " 0.005434172227978706,\n",
       " 0.00530105410143733,\n",
       " 0.005170806776732206,\n",
       " 0.005044684279710054,\n",
       " 0.004926076624542475,\n",
       " 0.00481560779735446,\n",
       " 0.0047092861495912075,\n",
       " 0.0046083987690508366,\n",
       " 0.004513363819569349,\n",
       " 0.00442033726722002,\n",
       " 0.0043302602134644985,\n",
       " 0.004245756193995476,\n",
       " 0.004164874088019133,\n",
       " 0.004085817839950323,\n",
       " 0.004011415410786867,\n",
       " 0.003939925227314234,\n",
       " 0.0038701535668224096,\n",
       " 0.003803251078352332,\n",
       " 0.0037391127552837133,\n",
       " 0.003677352098748088,\n",
       " 0.003617902984842658,\n",
       " 0.003559983568266034,\n",
       " 0.0035036467015743256,\n",
       " 0.00344939180649817,\n",
       " 0.0033968372736126184,\n",
       " 0.0033458250109106302,\n",
       " 0.0032970637548714876,\n",
       " 0.0032490771263837814,\n",
       " 0.0032023871317505836,\n",
       " 0.0031575204338878393,\n",
       " 0.003113300772383809,\n",
       " 0.003070154460147023,\n",
       " 0.003028430975973606,\n",
       " 0.002988007850944996,\n",
       " 0.002948156325146556,\n",
       " 0.0029094971250742674,\n",
       " 0.002871795790269971,\n",
       " 0.002834986662492156,\n",
       " 0.0027990613598376513,\n",
       " 0.002764003584161401,\n",
       " 0.0027295302134007215,\n",
       " 0.0026956882793456316,\n",
       " 0.002662831684574485,\n",
       " 0.002630768343806267,\n",
       " 0.0025995078030973673,\n",
       " 0.0025686610024422407,\n",
       " 0.0025386097840964794,\n",
       " 0.0025091462302953005,\n",
       " 0.0024804682470858097,\n",
       " 0.002452080836519599,\n",
       " 0.002424473874270916,\n",
       " 0.0023973407223820686,\n",
       " 0.002370683243498206,\n",
       " 0.00234449515119195,\n",
       " 0.0023190074134618044,\n",
       " 0.002293860772624612,\n",
       " 0.002269168384373188,\n",
       " 0.002244802890345454,\n",
       " 0.002220995957031846,\n",
       " 0.002197519177570939,\n",
       " 0.0021744018886238337,\n",
       " 0.002151563297957182,\n",
       " 0.0021292748861014843,\n",
       " 0.002107251202687621,\n",
       " 0.002085444750264287,\n",
       " 0.002064069267362356,\n",
       " 0.0020430139265954494,\n",
       " 0.0020223595201969147,\n",
       " 0.0020021989475935698,\n",
       " 0.0019820949528366327,\n",
       " 0.0019625697750598192,\n",
       " 0.0019431165419518948,\n",
       " 0.0019240042893216014,\n",
       " 0.0019049948314204812,\n",
       " 0.0018865031888708472,\n",
       " 0.0018679589265957475,\n",
       " 0.0018499194411560893,\n",
       " 0.0018323141848668456,\n",
       " 0.0018145195208489895,\n",
       " 0.0017971572233363986,\n",
       " 0.0017801891081035137,\n",
       " 0.0017635257681831717,\n",
       " 0.001746776164509356,\n",
       " 0.0017301604384556413,\n",
       " 0.0017141165444627404,\n",
       " 0.0016985624097287655,\n",
       " 0.001682937960140407,\n",
       " 0.001666994416154921,\n",
       " 0.001651815022341907,\n",
       " 0.0016374174738302827,\n",
       " 0.0016224798746407032,\n",
       " 0.0016073695151135325,\n",
       " 0.0015930522931739688,\n",
       " 0.0015788039891049266,\n",
       " 0.0015647519612684846,\n",
       " 0.0015505923656746745,\n",
       " 0.0015371982008218765,\n",
       " 0.0015240953071042895,\n",
       " 0.001510745263658464,\n",
       " 0.0014969833428040147,\n",
       " 0.0014843177050352097,\n",
       " 0.0014718176098540425,\n",
       " 0.0014592185616493225,\n",
       " 0.0014467047294601798,\n",
       " 0.0014342571375891566,\n",
       " 0.0014219438889995217,\n",
       " 0.0014098630053922534,\n",
       " 0.0013980503426864743,\n",
       " 0.0013868160312995315,\n",
       " 0.0013751490041613579,\n",
       " 0.0013643231941387057,\n",
       " 0.0013524265959858894,\n",
       " 0.0013412279076874256,\n",
       " 0.0013303286395967007,\n",
       " 0.0013195726787671447,\n",
       " 0.0013092360459268093,\n",
       " 0.0012981999898329377,\n",
       " 0.001288162893615663,\n",
       " 0.0012775355717167258,\n",
       " 0.0012671761214733124,\n",
       " 0.0012573859421536326,\n",
       " 0.0012472637463361025,\n",
       " 0.001237277640029788,\n",
       " 0.001227943110279739,\n",
       " 0.001218484714627266,\n",
       " 0.0012094654375687242,\n",
       " 0.0011993213556706905,\n",
       " 0.001190110808238387,\n",
       " 0.0011813706951215863,\n",
       " 0.001171073061414063,\n",
       " 0.0011626656632870436,\n",
       " 0.001154425204731524,\n",
       " 0.0011442489922046661,\n",
       " 0.001137188053689897,\n",
       " 0.0011272655101493,\n",
       " 0.001118680345825851,\n",
       " 0.0011107467580586672,\n",
       " 0.0011015841737389565,\n",
       " 0.0010940606007352471,\n",
       " 0.0010852367850020528,\n",
       " 0.0010774669935926795,\n",
       " 0.001069684512913227,\n",
       " 0.001061510294675827,\n",
       " 0.001053826417773962,\n",
       " 0.0010463516227900982,\n",
       " 0.0010382650652900338,\n",
       " 0.0010314880637452006,\n",
       " 0.0010240637930110097,\n",
       " 0.0010163414990529418,\n",
       " 0.0010095328325405717,\n",
       " 0.0010021753842011094,\n",
       " 0.0009948142105713487,\n",
       " 0.000988654443062842,\n",
       " 0.0009809773182496428,\n",
       " 0.0009742334950715303,\n",
       " 0.0009684371761977673,\n",
       " 0.0009606026578694582,\n",
       " 0.0009543047635816038,\n",
       " 0.0009480309672653675,\n",
       " 0.0009410444181412458,\n",
       " 0.0009350112522952259,\n",
       " 0.000929015688598156,\n",
       " 0.0009220478241331875,\n",
       " 0.0009166253730654716,\n",
       " 0.0009106310899369419,\n",
       " 0.0009036817937158048,\n",
       " 0.0008984548039734364,\n",
       " 0.0008921457920223475,\n",
       " 0.0008859597728587687,\n",
       " 0.0008804478566162288,\n",
       " 0.0008747913525439799,\n",
       " 0.0008687516674399376,\n",
       " 0.0008633406832814217,\n",
       " 0.0008577641565352678,\n",
       " 0.0008518570684827864,\n",
       " 0.000846348179038614,\n",
       " 0.0008413491304963827,\n",
       " 0.0008361604996025562,\n",
       " 0.0008301546913571656,\n",
       " 0.000825060298666358,\n",
       " 0.0008206844213418663,\n",
       " 0.0008146132458932698,\n",
       " 0.0008097777608782053,\n",
       " 0.000805515272077173,\n",
       " 0.0007996512576937675,\n",
       " 0.0007954869070090353,\n",
       " 0.0007911399006843567,\n",
       " 0.0007850654073990881,\n",
       " 0.0007821281324140728,\n",
       " 0.0007752222591079772,\n",
       " 0.000771472929045558,\n",
       " 0.0007660933770239353,\n",
       " 0.0007617361843585968,\n",
       " 0.0007570541347377002,\n",
       " 0.0007524599204771221,\n",
       " 0.0007479292689822614,\n",
       " 0.0007434419821947813,\n",
       " 0.0007388290832750499,\n",
       " 0.0007344952318817377,\n",
       " 0.0007299802382476628,\n",
       " 0.0007259119302034378,\n",
       " 0.0007213444332592189,\n",
       " 0.0007172095938585699,\n",
       " 0.0007132405298762023,\n",
       " 0.0007088184938766062,\n",
       " 0.0007049233536235988,\n",
       " 0.0007008400862105191,\n",
       " 0.000696407223585993,\n",
       " 0.0006927105132490396,\n",
       " 0.0006888835341669619,\n",
       " 0.0006846996839158237,\n",
       " 0.0006806469173170626,\n",
       " 0.0006770154577679932,\n",
       " 0.0006731036119163036,\n",
       " 0.0006694889743812382,\n",
       " 0.0006654956378042698,\n",
       " 0.0006618548068217933,\n",
       " 0.0006581565248779953,\n",
       " 0.0006548638339154422,\n",
       " 0.0006508652586489916,\n",
       " 0.0006473060930147767,\n",
       " 0.0006436405819840729,\n",
       " 0.0006401592982001603,\n",
       " 0.0006364934961311519,\n",
       " 0.0006331120966933668,\n",
       " 0.000629487622063607,\n",
       " 0.0006262364331632853,\n",
       " 0.0006228047423064709,\n",
       " 0.0006201109499670565,\n",
       " 0.0006162739591673017,\n",
       " 0.0006129856337793171,\n",
       " 0.0006108187371864915,\n",
       " 0.0006058957078494132,\n",
       " 0.0006042863242328167,\n",
       " 0.000600439787376672,\n",
       " 0.0005969623452983797,\n",
       " 0.0005944915465079248,\n",
       " 0.0005898955860175192,\n",
       " 0.0005872076726518571,\n",
       " 0.0005839172517880797,\n",
       " 0.0005804792162962258,\n",
       " 0.0005777866463176906,\n",
       " 0.0005744180525653064,\n",
       " 0.0005712537677027285,\n",
       " 0.0005682820337824523,\n",
       " 0.0005653469706885517,\n",
       " 0.0005621220916509628,\n",
       " 0.0005592134548351169,\n",
       " 0.000556355167645961,\n",
       " 0.0005533812218345702,\n",
       " 0.0005503306747414172,\n",
       " 0.0005474444478750229,\n",
       " 0.0005446829018183053,\n",
       " 0.0005419896333478391,\n",
       " 0.0005394161562435329,\n",
       " 0.0005362022202461958,\n",
       " 0.0005336313624866307,\n",
       " 0.0005313665606081486,\n",
       " 0.000528440868947655,\n",
       " 0.000525479088537395,\n",
       " 0.0005232495022937655,\n",
       " 0.000520288769621402,\n",
       " 0.000517392298206687,\n",
       " 0.000514834828209132,\n",
       " 0.000512383587192744,\n",
       " 0.000510011741425842,\n",
       " 0.0005072216154076159,\n",
       " 0.000504570547491312,\n",
       " 0.0005022494588047266,\n",
       " 0.0004998099175281823,\n",
       " 0.0004975579213351011,\n",
       " 0.0004946973640471697,\n",
       " 0.0004927952541038394,\n",
       " 0.0004910737625323236,\n",
       " 0.00048775121103972197,\n",
       " 0.00048669459647499025,\n",
       " 0.00048343176604248583,\n",
       " 0.00048101565334945917,\n",
       " 0.0004793819971382618,\n",
       " 0.00047616614028811455,\n",
       " 0.0004743504978250712,\n",
       " 0.0004718616546597332,\n",
       " 0.00046932976692914963,\n",
       " 0.0004674927331507206,\n",
       " 0.00046493232366628945,\n",
       " 0.0004633596690837294]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02da35",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T16:12:59.196397Z",
     "iopub.status.busy": "2023-12-02T16:12:59.196085Z",
     "iopub.status.idle": "2023-12-02T16:12:59.306438Z",
     "shell.execute_reply": "2023-12-02T16:12:59.305320Z",
     "shell.execute_reply.started": "2023-12-02T16:12:59.196372Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.056123,
     "end_time": "2023-12-02T18:38:57.723525",
     "exception": false,
     "start_time": "2023-12-02T18:38:57.667402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1616bf",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-12-02T16:33:18.596582Z",
     "iopub.status.busy": "2023-12-02T16:33:18.596172Z",
     "iopub.status.idle": "2023-12-02T16:33:18.608926Z",
     "shell.execute_reply": "2023-12-02T16:33:18.607790Z",
     "shell.execute_reply.started": "2023-12-02T16:33:18.596551Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.054767,
     "end_time": "2023-12-02T18:38:57.835080",
     "exception": false,
     "start_time": "2023-12-02T18:38:57.780313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1515974,
     "sourceId": 2503457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 187.726615,
   "end_time": "2023-12-02T18:38:59.015021",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-02T18:35:51.288406",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
