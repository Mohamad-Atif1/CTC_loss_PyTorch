{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2503457,"sourceType":"datasetVersion","datasetId":1515974}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport torch\nfrom torch import optim as opt\nfrom torch import nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader\nfrom sklearn import preprocessing \nfrom torchvision import transforms\nimport imageio as iio\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T13:07:54.706886Z","iopub.execute_input":"2023-12-03T13:07:54.707796Z","iopub.status.idle":"2023-12-03T13:08:01.298440Z","shell.execute_reply.started":"2023-12-03T13:07:54.707760Z","shell.execute_reply":"2023-12-03T13:08:01.296762Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"bs = 48\nnum_epochs = 700","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:01.303068Z","iopub.execute_input":"2023-12-03T13:08:01.303657Z","iopub.status.idle":"2023-12-03T13:08:01.311434Z","shell.execute_reply.started":"2023-12-03T13:08:01.303620Z","shell.execute_reply":"2023-12-03T13:08:01.309394Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"names = ['Amin','Farzad','Maziar','Mehrdad','Sina','Soheil','Vahid']\nname_file = {name:[] for name in names}\n\nfor dirname, _, filenames in os.walk('/kaggle/input/arabicpersian-handwritten-cities-for-postal-apps/scan splited/scan splited'):\n    filenames = sorted(filenames) # i want it to be on the same order\n    for filename in filenames:\n        name = dirname[89:]\n        name_file[name].append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:01.313093Z","iopub.execute_input":"2023-12-03T13:08:01.313987Z","iopub.status.idle":"2023-12-03T13:08:03.001602Z","shell.execute_reply.started":"2023-12-03T13:08:01.313953Z","shell.execute_reply":"2023-12-03T13:08:02.999891Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# I just want to take a subset of the dataset","metadata":{}},{"cell_type":"code","source":"alphabit = \"ابتثجحخدذرزسشصضطظعغفقكلمنهويئ\"\nnum_output = len(alphabit)\nalphabit = [a for a in alphabit]\nprint(num_output)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.004956Z","iopub.execute_input":"2023-12-03T13:08:03.006461Z","iopub.status.idle":"2023-12-03T13:08:03.014009Z","shell.execute_reply.started":"2023-12-03T13:08:03.006414Z","shell.execute_reply":"2023-12-03T13:08:03.011968Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"29\n","output_type":"stream"}]},{"cell_type":"code","source":"def pad_words(targets):\n    \"\"\"\n    Padding words to make all of them on the same size\n    \"\"\"\n    targets_new = []\n    for target in targets:\n        pad = 6-len(target)\n        targets_new.append(np.concatenate((np.ones(pad),target),axis=0).astype(np.longlong))\n        \n        \n    return targets_new","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.016391Z","iopub.execute_input":"2023-12-03T13:08:03.016772Z","iopub.status.idle":"2023-12-03T13:08:03.027016Z","shell.execute_reply.started":"2023-12-03T13:08:03.016737Z","shell.execute_reply":"2023-12-03T13:08:03.025902Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"words = (\" خيابان ميدان نمين ديلم مهران كاشان برحوار نائين البرز يزد تبريز سيريك\") # only these words will be considerd\nwords = words*4 # four persons wrote these words\nwords = words.split(' ')\nwords.__delitem__(0) # first element is just empty\n\n\nimgs = []\nfor name,files in name_file.items():\n    if  name.__eq__('Maziar') or name.__eq__('Mehrdad') or name.__eq__('Sina'):\n        continue\n    for i,file in enumerate(files):\n        if i == 12:\n            break\n        imgs.append(file)\n    \n\ntargets = [[w for w in word] for word in words]\nlbl_enc = preprocessing.LabelEncoder()\nlbl_enc.fit(alphabit)\ntargets_enc = [lbl_enc.transform(word)+2 for word in targets]\ntargets_enc = pad_words(targets_enc)\ndataset = {'imgs':imgs, \"labels\":targets_enc}\ndf = pd.DataFrame(dataset)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.029291Z","iopub.execute_input":"2023-12-03T13:08:03.029710Z","iopub.status.idle":"2023-12-03T13:08:03.058759Z","shell.execute_reply.started":"2023-12-03T13:08:03.029675Z","shell.execute_reply":"2023-12-03T13:08:03.057311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class Mydataset(Dataset):\n    \n    def __init__(self,df,trans=None):\n        self.df = df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        x = Image.open(self.df['imgs'][idx]).convert('RGB')\n        if trans:\n            x = trans(x)\n        y = self.df['labels'][idx] # +1 i have already add one in the above cell \n        return (x,y)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.059877Z","iopub.execute_input":"2023-12-03T13:08:03.060284Z","iopub.status.idle":"2023-12-03T13:08:03.072226Z","shell.execute_reply.started":"2023-12-03T13:08:03.060245Z","shell.execute_reply":"2023-12-03T13:08:03.070586Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# std = torch.tensor([0.0603, 0.0606, 0.0347])\n# mean = torch.tensor([[0.8753, 0.8924, 0.9244]])\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.073886Z","iopub.execute_input":"2023-12-03T13:08:03.074729Z","iopub.status.idle":"2023-12-03T13:08:03.088976Z","shell.execute_reply.started":"2023-12-03T13:08:03.074696Z","shell.execute_reply":"2023-12-03T13:08:03.087863Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trans = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize(size=(20,80)),\n    transforms.Normalize(mean=(0.8753,0.8924,0.9244),std=(0.0603,0.0606,0.0347))\n                           ])\nall_imgs = []\ndataset = Mydataset(df,trans)\n\n    \n\ntrain_loader = DataLoader(dataset,batch_size=bs)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.090345Z","iopub.execute_input":"2023-12-03T13:08:03.090630Z","iopub.status.idle":"2023-12-03T13:08:03.100034Z","shell.execute_reply.started":"2023-12-03T13:08:03.090607Z","shell.execute_reply":"2023-12-03T13:08:03.098982Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"\ndef decode_pred(y_pred,targets):\n    \"\"\"\n    applying inverse_transform to convert numbers to characters\n    \"\"\"    \n    # first we need to remove blanks(0) and padding (1)\n    targets_filtered = [target[(target!=0) & (target!=1)]-2 for target in targets] \n    y_pred = torch.argmax(y_pred,dim=2).permute(1,0) \n    y_pred_filtered = [y[(y!=0) & (y!=1)]-2 for y in y_pred]\n\n    targets_dec = [lbl_enc.inverse_transform(tf) for tf in targets_filtered ]\n    y_pred_dec = [lbl_enc.inverse_transform(yf) for yf in y_pred_filtered ]\n    results = {\n        'targets_filtered':targets_filtered,\n        'y_pred_filtered':y_pred_filtered,\n        'targets_dec':targets_dec,\n        'y_pred_dec':y_pred_dec\n              }\n    return results\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.102543Z","iopub.execute_input":"2023-12-03T13:08:03.102873Z","iopub.status.idle":"2023-12-03T13:08:03.117726Z","shell.execute_reply.started":"2023-12-03T13:08:03.102844Z","shell.execute_reply":"2023-12-03T13:08:03.116558Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"feature_map = torch.tensor([48, 84, 5, 20]) # bs,c,h,w\n\nclass MyCNN(nn.Module):\n    \n    def __init__(self):\n        super(MyCNN,self).__init__()\n        self.conv1 = nn.Conv2d(3,12,3,2,padding=1)\n        self.conv2 = nn.Conv2d(12,36,3,2,padding=1)\n        self.conv3 = nn.Conv2d(36,84,3,1,padding=1)\n        \n    def forward(self,x):\n        x = self.conv1(F.relu(x))\n#         print(x.shape)\n        x = self.conv2(F.relu(x))\n#         print(x.shape)\n        x = self.conv3(F.relu(x))\n        return x\n    \nclass MyRNN(nn.Module):\n    \n    def __init__(self,input_size,hidden_size,num_layers,bi):\n        super(MyRNN,self).__init__()\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers        \n        self.bi = bi\n        self.D = 2 if self.bi else 1 \n        self.gru = nn.GRU(input_size,hidden_size,num_layers,bidirectional=bi,batch_first=True)\n        self.linear1 = nn.Linear(self.D*hidden_size,self.D*hidden_size)\n        self.linear2 = nn.Linear(self.D*hidden_size,num_output+2) # +2 for the blank ctc and padding\n        \n        \n    def forward(self,x): \n        # x : (bs,T,features)\n        h0 = torch.zeros(self.D*self.num_layers,x.size(0),self.hidden_size)\n        out,hn = self.gru(x,h0)\n        out = self.linear1(F.relu(out))\n        out = self.linear2(out)\n        out = F.log_softmax(out,dim=2)\n        out = out.permute(1,0,2)\n        return out\n        \n        \n    \n    \nclass MyModel(nn.Module):\n    \n    def __init__(self,hidden_size,num_layers,bi):\n        super(MyModel,self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers  \n        self.bi = bi\n        self.cnn = MyCNN()\n        self.rnn = MyRNN(feature_map[1]*feature_map[2],hidden_size,num_layers,bi)\n        \n    def forward(self,x):\n        x = self.cnn(x)\n#         print(x.shape) # --> (bs,c,h,w)\n        x = x.view(-1,x.shape[3],x.shape[2]*x.shape[1]) # --> (bs,w,h*c)\n        \n        # i will assume that num of channels is the time_stamps \n        # i've changed my mind :) , w = time_stamps\n        # for rnn , we need (time_stamps,bs,featuers)\n        \n        x = self.rnn(x)\n        \n        return x\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.118904Z","iopub.execute_input":"2023-12-03T13:08:03.120084Z","iopub.status.idle":"2023-12-03T13:08:03.155880Z","shell.execute_reply.started":"2023-12-03T13:08:03.120054Z","shell.execute_reply":"2023-12-03T13:08:03.154316Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"loss_fn =  nn.CTCLoss(blank=0)\nmodel = MyModel(300,2,True)\nlr = 1e-3\noptim = opt.Adam(model.parameters(),lr=lr) \n\nbatch = next(iter(train_loader))       \ntrain_loss = []\nfor epoch in range (num_epochs):\n    losses = 0\n    for batch in train_loader:\n        x,y = batch[0],batch[1]\n        out = model(batch[0])\n        input_lengths = torch.full(size=(x.shape[0],), fill_value=out.shape[0], dtype=torch.long)\n        target_lengths = torch.full(size=(x.shape[0],), fill_value=batch[1].size(1), dtype=torch.long)\n        optim.zero_grad()\n        loss = loss_fn(out,batch[1],input_lengths,target_lengths)\n        loss.backward()\n        optim.step()\n        losses += loss.item()\n    print(epoch)    \n    train_loss.append(losses/len(train_loader))    \n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:08:03.158084Z","iopub.execute_input":"2023-12-03T13:08:03.158614Z","iopub.status.idle":"2023-12-03T13:10:48.083787Z","shell.execute_reply.started":"2023-12-03T13:08:03.158581Z","shell.execute_reply":"2023-12-03T13:10:48.082293Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n170\n171\n172\n173\n174\n175\n176\n177\n178\n179\n180\n181\n182\n183\n184\n185\n186\n187\n188\n189\n190\n191\n192\n193\n194\n195\n196\n197\n198\n199\n200\n201\n202\n203\n204\n205\n206\n207\n208\n209\n210\n211\n212\n213\n214\n215\n216\n217\n218\n219\n220\n221\n222\n223\n224\n225\n226\n227\n228\n229\n230\n231\n232\n233\n234\n235\n236\n237\n238\n239\n240\n241\n242\n243\n244\n245\n246\n247\n248\n249\n250\n251\n252\n253\n254\n255\n256\n257\n258\n259\n260\n261\n262\n263\n264\n265\n266\n267\n268\n269\n270\n271\n272\n273\n274\n275\n276\n277\n278\n279\n280\n281\n282\n283\n284\n285\n286\n287\n288\n289\n290\n291\n292\n293\n294\n295\n296\n297\n298\n299\n300\n301\n302\n303\n304\n305\n306\n307\n308\n309\n310\n311\n312\n313\n314\n315\n316\n317\n318\n319\n320\n321\n322\n323\n324\n325\n326\n327\n328\n329\n330\n331\n332\n333\n334\n335\n336\n337\n338\n339\n340\n341\n342\n343\n344\n345\n346\n347\n348\n349\n350\n351\n352\n353\n354\n355\n356\n357\n358\n359\n360\n361\n362\n363\n364\n365\n366\n367\n368\n369\n370\n371\n372\n373\n374\n375\n376\n377\n378\n379\n380\n381\n382\n383\n384\n385\n386\n387\n388\n389\n390\n391\n392\n393\n394\n395\n396\n397\n398\n399\n400\n401\n402\n403\n404\n405\n406\n407\n408\n409\n410\n411\n412\n413\n414\n415\n416\n417\n418\n419\n420\n421\n422\n423\n424\n425\n426\n427\n428\n429\n430\n431\n432\n433\n434\n435\n436\n437\n438\n439\n440\n441\n442\n443\n444\n445\n446\n447\n448\n449\n450\n451\n452\n453\n454\n455\n456\n457\n458\n459\n460\n461\n462\n463\n464\n465\n466\n467\n468\n469\n470\n471\n472\n473\n474\n475\n476\n477\n478\n479\n480\n481\n482\n483\n484\n485\n486\n487\n488\n489\n490\n491\n492\n493\n494\n495\n496\n497\n498\n499\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluating","metadata":{}},{"cell_type":"code","source":"decode_pred(out,batch[1])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:10:48.085437Z","iopub.execute_input":"2023-12-03T13:10:48.085872Z","iopub.status.idle":"2023-12-03T13:10:48.134661Z","shell.execute_reply.started":"2023-12-03T13:10:48.085802Z","shell.execute_reply":"2023-12-03T13:10:48.133053Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'targets_filtered': [tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 25]),\n  tensor([ 8, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 11,  8]),\n  tensor([ 3,  2, 10, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 25]),\n  tensor([ 8, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 11,  8]),\n  tensor([ 3,  2, 10, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 25]),\n  tensor([ 8, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 11,  8]),\n  tensor([ 3,  2, 10, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 25]),\n  tensor([ 8, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 11,  8]),\n  tensor([ 3,  2, 10, 28, 11]),\n  tensor([12, 28, 10, 28, 22])],\n 'y_pred_filtered': [tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 28, 28, 25]),\n  tensor([ 8, 28, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 28, 28, 11,  8]),\n  tensor([ 3,  3,  2, 10, 28, 28, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 28, 28, 25]),\n  tensor([ 8, 28, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 28, 28, 11,  8]),\n  tensor([ 3,  3,  2, 10, 28, 28, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 28, 28, 25]),\n  tensor([ 8, 28, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 28, 28, 11,  8]),\n  tensor([ 3,  3,  2, 10, 28, 28, 28, 11]),\n  tensor([12, 28, 10, 28, 22]),\n  tensor([ 7, 28,  1,  2,  1, 25]),\n  tensor([24, 28,  8,  1, 25]),\n  tensor([25, 24, 28, 28, 28, 25]),\n  tensor([ 8, 28, 28, 23, 24]),\n  tensor([24, 26, 10,  1, 25]),\n  tensor([22,  1, 13,  1, 25]),\n  tensor([ 2, 10,  6, 27,  1, 10]),\n  tensor([25,  1,  0, 28, 28, 25]),\n  tensor([ 1, 23,  2, 10, 11]),\n  tensor([28, 28, 28, 11,  8]),\n  tensor([ 3,  3,  2, 10, 28, 28, 28, 11]),\n  tensor([12, 28, 10, 28, 22])],\n 'targets_dec': [array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ب', 'ر', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1')],\n 'y_pred_dec': [array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ي', 'ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ت', 'ب', 'ر', 'ي', 'ي', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ي', 'ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ت', 'ب', 'ر', 'ي', 'ي', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ي', 'ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ت', 'ب', 'ر', 'ي', 'ي', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1'),\n  array(['خ', 'ي', 'ا', 'ب', 'ا', 'ن'], dtype='<U1'),\n  array(['م', 'ي', 'د', 'ا', 'ن'], dtype='<U1'),\n  array(['ن', 'م', 'ي', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['د', 'ي', 'ي', 'ل', 'م'], dtype='<U1'),\n  array(['م', 'ه', 'ر', 'ا', 'ن'], dtype='<U1'),\n  array(['ك', 'ا', 'ش', 'ا', 'ن'], dtype='<U1'),\n  array(['ب', 'ر', 'ح', 'و', 'ا', 'ر'], dtype='<U1'),\n  array(['ن', 'ا', 'ئ', 'ي', 'ي', 'ن'], dtype='<U1'),\n  array(['ا', 'ل', 'ب', 'ر', 'ز'], dtype='<U1'),\n  array(['ي', 'ي', 'ي', 'ز', 'د'], dtype='<U1'),\n  array(['ت', 'ت', 'ب', 'ر', 'ي', 'ي', 'ي', 'ز'], dtype='<U1'),\n  array(['س', 'ي', 'ر', 'ي', 'ك'], dtype='<U1')]}"},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(train_loss)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:10:48.136991Z","iopub.execute_input":"2023-12-03T13:10:48.137372Z","iopub.status.idle":"2023-12-03T13:10:48.359483Z","shell.execute_reply.started":"2023-12-03T13:10:48.137349Z","shell.execute_reply":"2023-12-03T13:10:48.357873Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7b38d43d2860>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"train_loss","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:10:48.361002Z","iopub.execute_input":"2023-12-03T13:10:48.361452Z","iopub.status.idle":"2023-12-03T13:10:48.374231Z","shell.execute_reply.started":"2023-12-03T13:10:48.361416Z","shell.execute_reply":"2023-12-03T13:10:48.373171Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[8.797357559204102,\n 8.30746078491211,\n 7.310892581939697,\n 5.088986873626709,\n 3.3600752353668213,\n 4.420230865478516,\n 3.5836679935455322,\n 2.9588191509246826,\n 3.184907913208008,\n 3.361034393310547,\n 3.219707727432251,\n 2.954174280166626,\n 2.824835777282715,\n 2.9190127849578857,\n 2.9936106204986572,\n 2.892700433731079,\n 2.734816789627075,\n 2.675518035888672,\n 2.7200546264648438,\n 2.7540338039398193,\n 2.707984209060669,\n 2.614332914352417,\n 2.5419921875,\n 2.524650812149048,\n 2.534536838531494,\n 2.521789312362671,\n 2.474579095840454,\n 2.423449993133545,\n 2.398463487625122,\n 2.3949267864227295,\n 2.3871500492095947,\n 2.362793445587158,\n 2.3296196460723877,\n 2.299987554550171,\n 2.279383659362793,\n 2.2645161151885986,\n 2.248208999633789,\n 2.2263705730438232,\n 2.2018074989318848,\n 2.180126428604126,\n 2.162907123565674,\n 2.1481096744537354,\n 2.131601333618164,\n 2.1116812229156494,\n 2.0904624462127686,\n 2.0702085494995117,\n 2.052469253540039,\n 2.0379087924957275,\n 2.0269436836242676,\n 2.0151805877685547,\n 1.9988936185836792,\n 1.9796689748764038,\n 1.961776852607727,\n 1.9454058408737183,\n 1.927939772605896,\n 1.9088455438613892,\n 1.8901604413986206,\n 1.8735970258712769,\n 1.8570667505264282,\n 1.8402601480484009,\n 1.8237576484680176,\n 1.8086620569229126,\n 1.7954769134521484,\n 1.7823152542114258,\n 1.7699154615402222,\n 1.7591581344604492,\n 1.749237060546875,\n 1.7409662008285522,\n 1.7342267036437988,\n 1.7326312065124512,\n 1.7431588172912598,\n 1.7158350944519043,\n 1.7203081846237183,\n 1.7300004959106445,\n 1.7056292295455933,\n 1.7270317077636719,\n 1.7142361402511597,\n 1.7211856842041016,\n 1.6866620779037476,\n 1.7050834894180298,\n 1.6774344444274902,\n 1.689616322517395,\n 1.6621774435043335,\n 1.6636658906936646,\n 1.6435414552688599,\n 1.6368542909622192,\n 1.6302169561386108,\n 1.6084102392196655,\n 1.6123441457748413,\n 1.591564655303955,\n 1.6102313995361328,\n 1.6281251907348633,\n 1.6055908203125,\n 1.552363395690918,\n 1.5812312364578247,\n 1.5796804428100586,\n 1.5173463821411133,\n 1.5530858039855957,\n 1.515939712524414,\n 1.5063742399215698,\n 1.5120028257369995,\n 1.4733119010925293,\n 1.4836684465408325,\n 1.4678674936294556,\n 1.4464765787124634,\n 1.4548228979110718,\n 1.443031907081604,\n 1.415598750114441,\n 1.4259194135665894,\n 1.419476866722107,\n 1.3807271718978882,\n 1.3937486410140991,\n 1.364402413368225,\n 1.3453763723373413,\n 1.353363037109375,\n 1.3337675333023071,\n 1.306166648864746,\n 1.301242709159851,\n 1.3038655519485474,\n 1.265645146369934,\n 1.2592335939407349,\n 1.2658218145370483,\n 1.2430423498153687,\n 1.2036324739456177,\n 1.2094699144363403,\n 1.2411744594573975,\n 1.2687922716140747,\n 1.163933277130127,\n 1.2640661001205444,\n 1.1567339897155762,\n 1.2210018634796143,\n 1.1392194032669067,\n 1.1771588325500488,\n 1.109242558479309,\n 1.095171570777893,\n 1.0737007856369019,\n 1.0378451347351074,\n 1.0356460809707642,\n 1.0022621154785156,\n 1.0776995420455933,\n 1.3463555574417114,\n 1.0393825769424438,\n 1.6167770624160767,\n 1.0593103170394897,\n 1.29459547996521,\n 1.186659812927246,\n 1.0163345336914062,\n 1.1127804517745972,\n 1.0411556959152222,\n 0.9640681743621826,\n 0.9869378209114075,\n 0.9428389668464661,\n 0.8794364929199219,\n 0.9143922924995422,\n 0.8718338012695312,\n 0.8341031074523926,\n 0.8202619552612305,\n 0.7881197929382324,\n 0.7595372796058655,\n 0.7486204504966736,\n 0.7152485251426697,\n 0.7070251107215881,\n 0.711764395236969,\n 0.7990626692771912,\n 0.8828452229499817,\n 0.6481721997261047,\n 0.7300949692726135,\n 0.6904508471488953,\n 0.6010432839393616,\n 0.668026864528656,\n 0.5084580779075623,\n 0.5959778428077698,\n 0.4876512587070465,\n 0.5058527588844299,\n 0.4511518180370331,\n 0.45702481269836426,\n 0.4009213149547577,\n 0.4078749120235443,\n 0.36645233631134033,\n 0.3619033992290497,\n 0.31742730736732483,\n 0.32219958305358887,\n 0.27552953362464905,\n 0.28682807087898254,\n 0.23910267651081085,\n 0.2540884017944336,\n 0.2182202935218811,\n 0.2413318157196045,\n 0.23580485582351685,\n 0.2561742961406708,\n 0.3015879988670349,\n 0.3140585720539093,\n 0.211783304810524,\n 0.17415042221546173,\n 0.185629740357399,\n 0.14165101945400238,\n 0.14371368288993835,\n 0.13875359296798706,\n 0.11590007692575455,\n 0.118166983127594,\n 0.1091514602303505,\n 0.09874812513589859,\n 0.08675824850797653,\n 0.08983886986970901,\n 0.07686448842287064,\n 0.07141604274511337,\n 0.06883092224597931,\n 0.06089475750923157,\n 0.0596277117729187,\n 0.05570858344435692,\n 0.04898728057742119,\n 0.046576838940382004,\n 0.044687364250421524,\n 0.04161052778363228,\n 0.03831914812326431,\n 0.03457697853446007,\n 0.03255891799926758,\n 0.03183458372950554,\n 0.02902469038963318,\n 0.026478832587599754,\n 0.02507614903151989,\n 0.023508382961153984,\n 0.02218172512948513,\n 0.020878175273537636,\n 0.019239677116274834,\n 0.017954234033823013,\n 0.017054567113518715,\n 0.016022302210330963,\n 0.015064146369695663,\n 0.014343704096972942,\n 0.013526282273232937,\n 0.012663793750107288,\n 0.012021318078041077,\n 0.011485467664897442,\n 0.010908789001405239,\n 0.010380498133599758,\n 0.009937332011759281,\n 0.009494832716882229,\n 0.009048132225871086,\n 0.008652826771140099,\n 0.008310575038194656,\n 0.007985091768205166,\n 0.007678162306547165,\n 0.007415608037263155,\n 0.007182398345321417,\n 0.006946448236703873,\n 0.00670275092124939,\n 0.006478972267359495,\n 0.006286073941737413,\n 0.006113737355917692,\n 0.005946252029389143,\n 0.005783051252365112,\n 0.005629850085824728,\n 0.005486916750669479,\n 0.00535140186548233,\n 0.005220882594585419,\n 0.00509830703958869,\n 0.004984739702194929,\n 0.004877130035310984,\n 0.004773623775690794,\n 0.004672528710216284,\n 0.004575891885906458,\n 0.004484782461076975,\n 0.0043991925194859505,\n 0.004315195605158806,\n 0.004232764709740877,\n 0.004154104273766279,\n 0.004080156795680523,\n 0.004009873140603304,\n 0.003941392060369253,\n 0.0038744015619158745,\n 0.0038095361087471247,\n 0.0037475749850273132,\n 0.0036880013067275286,\n 0.003629967337474227,\n 0.0035732814576476812,\n 0.003518759272992611,\n 0.003465874120593071,\n 0.0034144537057727575,\n 0.0033645278308540583,\n 0.003316042711958289,\n 0.0032691191881895065,\n 0.003223394975066185,\n 0.0031788472551852465,\n 0.0031353160738945007,\n 0.003093118080869317,\n 0.0030521610751748085,\n 0.0030121321324259043,\n 0.002973114140331745,\n 0.0029350484255701303,\n 0.002897975966334343,\n 0.0028618669603019953,\n 0.0028265349101275206,\n 0.0027919181156903505,\n 0.0027582282200455666,\n 0.002725427271798253,\n 0.0026934854686260223,\n 0.0026621755678206682,\n 0.0026314177084714174,\n 0.002601456828415394,\n 0.0025721958372741938,\n 0.0025435585994273424,\n 0.0025154200848191977,\n 0.0024878059048205614,\n 0.0024607565719634295,\n 0.00243429490365088,\n 0.002408273983746767,\n 0.0023826989345252514,\n 0.0023576414678245783,\n 0.0023330969270318747,\n 0.002308969385921955,\n 0.002285197377204895,\n 0.0022618870716542006,\n 0.002239090157672763,\n 0.002216639230027795,\n 0.0021945901680737734,\n 0.0021730849985033274,\n 0.0021519854199141264,\n 0.0021313363686203957,\n 0.0021109271328896284,\n 0.0020908501464873552,\n 0.002071056282147765,\n 0.002051673596724868,\n 0.0020325800869613886,\n 0.002013777382671833,\n 0.00199527177028358,\n 0.0019769801292568445,\n 0.0019590321462601423,\n 0.0019412986002862453,\n 0.0019238748354837298,\n 0.0019066124223172665,\n 0.0018895933171734214,\n 0.0018728672293946147,\n 0.0018563215853646398,\n 0.0018400390399619937,\n 0.0018240261124446988,\n 0.0018082964234054089,\n 0.0017928131856024265,\n 0.0017775207525119185,\n 0.001762552186846733,\n 0.001747734728269279,\n 0.0017330767586827278,\n 0.0017185742035508156,\n 0.001704361871816218,\n 0.0016903307987377048,\n 0.0016764472238719463,\n 0.0016628401353955269,\n 0.0016494463197886944,\n 0.0016362429596483707,\n 0.0016231629997491837,\n 0.0016103261150419712,\n 0.0015976453432813287,\n 0.0015850579366087914,\n 0.0015726768178865314,\n 0.001560457982122898,\n 0.0015483949100598693,\n 0.0015364257851615548,\n 0.0015246426919475198,\n 0.0015129485400393605,\n 0.0015014841919764876,\n 0.0014901329996064305,\n 0.001478913240134716,\n 0.0014678348088636994,\n 0.0014569401973858476,\n 0.0014462185790762305,\n 0.001435601618140936,\n 0.001425142982043326,\n 0.0014147943584248424,\n 0.001404561917297542,\n 0.0013944786041975021,\n 0.001384484232403338,\n 0.0013745991745963693,\n 0.0013648621970787644,\n 0.0013553161406889558,\n 0.0013457933673635125,\n 0.0013363845646381378,\n 0.0013270623749122024,\n 0.0013179248198866844,\n 0.001308848732151091,\n 0.0012998593738302588,\n 0.0012909824727103114,\n 0.0012821899726986885,\n 0.0012735869968309999,\n 0.0012650171993300319,\n 0.0012565357610583305,\n 0.0012481804005801678,\n 0.0012399292318150401,\n 0.0012317448854446411,\n 0.001223629922606051,\n 0.0012156107695773244,\n 0.001207734108902514,\n 0.0011998947011306882,\n 0.0011921367840841413,\n 0.001184492721222341,\n 0.0011769107077270746,\n 0.0011693889973685145,\n 0.0011619576252996922,\n 0.001154633122496307,\n 0.0011473874328657985,\n 0.0011401585070416331,\n 0.0011330603156238794,\n 0.0011260459432378411,\n 0.0011190541554242373,\n 0.0011121804127469659,\n 0.0011053336784243584,\n 0.001098629436455667,\n 0.0010919654741883278,\n 0.0010853634448722005,\n 0.001078824163414538,\n 0.0010723813902586699,\n 0.001065955962985754,\n 0.0010596433421596885,\n 0.0010533409658819437,\n 0.0010471380082890391,\n 0.0010409971000626683,\n 0.001034923130646348,\n 0.001028910162858665,\n 0.0010229593608528376,\n 0.0010170507011935115,\n 0.001011196756735444,\n 0.0010054061422124505,\n 0.0009996622102335095,\n 0.0009939706651493907,\n 0.0009883370948955417,\n 0.0009827676694840193,\n 0.0009772302582859993,\n 0.0009717547218315303,\n 0.0009663401287980378,\n 0.0009609546395950019,\n 0.0009556444711051881,\n 0.0009503876208327711,\n 0.0009451373480260372,\n 0.0009399547125212848,\n 0.0009348581661470234,\n 0.0009297565557062626,\n 0.0009247225825674832,\n 0.0009196907631121576,\n 0.0009147503296844661,\n 0.0009098449372686446,\n 0.0009049699292518198,\n 0.0009001327562145889,\n 0.0008953486103564501,\n 0.00089063192717731,\n 0.0008859083172865212,\n 0.0008812369196675718,\n 0.0008766080718487501,\n 0.000872041389811784,\n 0.0008674764540046453,\n 0.0008629642543382943,\n 0.0008584852330386639,\n 0.0008540498092770576,\n 0.0008496891823597252,\n 0.0008453243062831461,\n 0.0008410210139118135,\n 0.0008367230766452849,\n 0.0008324499358423054,\n 0.0008282521739602089,\n 0.0008240630850195885,\n 0.0008199132862500846,\n 0.0008157933480106294,\n 0.0008117193356156349,\n 0.0008076831582002342,\n 0.000803675502538681,\n 0.0007996853091754019,\n 0.0007957496563903987,\n 0.0007918085320852697,\n 0.000787928409408778,\n 0.0007840655744075775,\n 0.0007802261970937252,\n 0.000776449276600033,\n 0.0007726672920398414,\n 0.0007689360063523054,\n 0.0007652061176486313,\n 0.0007615615613758564,\n 0.0007578916265629232,\n 0.0007542879320681095,\n 0.000750682142097503,\n 0.0007471310091204941,\n 0.000743598910048604,\n 0.0007400783360935748,\n 0.0007366255740635097,\n 0.0007331487722694874,\n 0.0007297171396203339,\n 0.0007263203151524067,\n 0.0007229396724142134,\n 0.0007195744547061622,\n 0.0007162269321270287,\n 0.0007129363366402686,\n 0.0007096388726495206,\n 0.0007063699304126203,\n 0.000703128520399332,\n 0.0006999093457125127,\n 0.0006967218942008913,\n 0.0006935263518244028,\n 0.0006903880275785923,\n 0.0006872548838146031,\n 0.0006841467111371458,\n 0.0006810728809796274,\n 0.0006780020776204765,\n 0.0006749674212187529]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}